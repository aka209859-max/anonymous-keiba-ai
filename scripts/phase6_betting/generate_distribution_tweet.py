# -*- coding: utf-8 -*-
"""
ãƒ„ã‚¤ãƒ¼ãƒˆç”¨ã‚³ãƒ”ãƒšãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
åœ°æ–¹ç«¶é¦¬AIäºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ  - Phase 6 TwitteræŠ•ç¨¿ç”¨
å…¨14ç«¶é¦¬å ´å¯¾å¿œ
"""

import sys
import pandas as pd
from pathlib import Path
from datetime import datetime


def safe_print(msg):
    """å®‰å…¨ãªå‡ºåŠ›ï¼ˆWindows CP932å¯¾å¿œï¼‰"""
    try:
        print(msg)
    except UnicodeEncodeError:
        print(msg.encode('cp932', errors='ignore').decode('cp932'))


def load_horse_names_from_raw(ensemble_csv_path):
    """
    raw CSV ã‹ã‚‰é¦¬åã‚’å–å¾—ã—ã¦ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
    
    Args:
        ensemble_csv_path: ensemble CSV ã®ãƒ‘ã‚¹
    
    Returns:
        dict: {(kaisai_nen, kaisai_tsukihi, race_bango, umaban): bamei}
    """
    ensemble_path = Path(ensemble_csv_path)
    filename = ensemble_path.stem
    keibajo_date = filename.replace('_ensemble', '')
    
    parts = keibajo_date.split('_')
    if len(parts) < 2:
        return {}
    
    date_short = parts[1]
    year = date_short[:4]
    month = date_short[4:6]
    
    raw_csv_path = ensemble_path.parent.parent.parent / 'raw' / year / month / f"{keibajo_date}_raw.csv"
    
    safe_print(f"[INFO] Loading horse names from: {raw_csv_path}")
    
    if not raw_csv_path.exists():
        safe_print(f"[WARN] raw CSV not found: {raw_csv_path}")
        return {}
    
    try:
        df_raw = pd.read_csv(raw_csv_path, encoding='utf-8')
    except UnicodeDecodeError:
        df_raw = pd.read_csv(raw_csv_path, encoding='shift-jis')
    
    horse_names = {}
    
    required_cols = ['kaisai_nen', 'kaisai_tsukihi', 'race_bango', 'umaban', 'bamei']
    if all(col in df_raw.columns for col in required_cols):
        for _, row in df_raw.iterrows():
            key = (
                str(row['kaisai_nen']),
                str(row['kaisai_tsukihi']),
                str(row['race_bango']),
                int(row['umaban'])
            )
            horse_names[key] = str(row['bamei']).strip()
        
        safe_print(f"[OK] Horse name mapping created: {len(horse_names)} entries")
    else:
        safe_print(f"[WARN] Required columns not found in raw CSV")
    
    return horse_names


def get_horse_name(row, horse_names):
    """é¦¬åã‚’å–å¾—"""
    if 'bamei' in row and pd.notna(row['bamei']) and str(row['bamei']).strip():
        name = str(row['bamei']).strip()
        if name.endswith('å·'):
            name = name[:-1]
        return name
    
    key = (
        str(row['kaisai_nen']),
        str(row['kaisai_tsukihi']),
        str(row['race_bango']),
        int(row['umaban'])
    )
    
    if key in horse_names:
        name = horse_names[key]
        if name.endswith('å·'):
            name = name[:-1]
        return name
    
    return "æœªç™»éŒ²"


def generate_tweet_format(df_race):
    """
    ãƒ„ã‚¤ãƒ¼ãƒˆç”¨ã‚³ãƒ”ãƒšãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç”Ÿæˆ
    
    Args:
        df_race: ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrameã®1ãƒ¬ãƒ¼ã‚¹åˆ†ï¼‰
    
    Returns:
        str: ãƒ„ã‚¤ãƒ¼ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆ
    """
    top_horses = df_race.nsmallest(7, 'final_rank')['umaban'].tolist()
    
    if len(top_horses) < 3:
        return ""
    
    h1 = top_horses[0]
    h2 = top_horses[1] if len(top_horses) > 1 else None
    h3 = top_horses[2] if len(top_horses) > 2 else None
    h4 = top_horses[3] if len(top_horses) > 3 else None
    h5 = top_horses[4] if len(top_horses) > 4 else None
    h6 = top_horses[5] if len(top_horses) > 5 else None
    
    top5 = top_horses[:5] if len(top_horses) >= 5 else top_horses
    top7 = top_horses if len(top_horses) >= 7 else top_horses
    
    # 2ç€å€™è£œ: 2,3,4ä½
    second_place = [h2, h3, h4] if h2 and h3 and h4 else []
    second_place = [h for h in second_place if h is not None]
    
    # 3ç€å€™è£œ: 2,3,4,5,6,7ä½ï¼ˆä¸Šä½7é ­ã‹ã‚‰1ä½ã‚’é™¤å¤–ï¼‰
    third_place = top7[1:] if len(top7) > 1 else []
    
    # é¦¬å˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    umatan_parts = []
    if h2:
        umatan_parts.extend([f"{h1}â†’{h2}", f"{h2}â†’{h1}"])
    if h3:
        umatan_parts.extend([f"{h1}â†’{h3}", f"{h3}â†’{h1}"])
    
    umatan_str = "ã€".join(umatan_parts) if umatan_parts else f"{h1}è»¸"
    
    # ä¸‰é€£è¤‡BOX
    sanrenpuku_str = f"{'.'.join(map(str, top5))} BOX" if len(top5) >= 3 else ""
    
    # ä¸‰é€£å˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    if second_place and third_place:
        second_str = '.'.join(map(str, second_place))
        third_str = '.'.join(map(str, third_place))
        sanrentan_str = f"{h1}â†’{second_str}â†’{third_str}"
    else:
        sanrentan_str = f"{h1}è»¸"
    
    tweet = [
        "ğŸ“Š è³¼å…¥æ¨å¥¨",
        f"ãƒ»å˜å‹: {h1}ç•ª",
        f"ãƒ»è¤‡å‹: {h1}ç•ªã€{h2}ç•ª" if h2 else f"ãƒ»è¤‡å‹: {h1}ç•ª",
        f"ãƒ»é¦¬å˜: {umatan_str}",
        f"ãƒ»ä¸‰é€£è¤‡: {sanrenpuku_str}" if sanrenpuku_str else "",
        f"ãƒ»ä¸‰é€£å˜: {sanrentan_str}"
    ]
    
    return "\n".join([line for line in tweet if line])


def generate_distribution_text_tweet(input_csv, output_txt):
    """
    ãƒ„ã‚¤ãƒ¼ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
    
    Args:
        input_csv (str): å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        output_txt (str): å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    safe_print("[INFO] Tweet format generation started")
    safe_print(f"  Input: {input_csv}")
    safe_print(f"  Output: {output_txt}")
    
    try:
        df = pd.read_csv(input_csv, encoding='shift-jis')
    except UnicodeDecodeError:
        df = pd.read_csv(input_csv, encoding='utf-8')
    
    required_cols = ['race_bango', 'umaban', 'ensemble_score', 'final_rank']
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        safe_print(f"[ERROR] Missing required columns: {missing_cols}")
        return
    
    horse_names = load_horse_names_from_raw(input_csv)
    
    output_path = Path(output_txt)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ç«¶é¦¬å ´åã¨æ—¥ä»˜ã‚’æŠ½å‡º
    filename = Path(input_csv).stem
    keibajo_date = filename.replace('_ensemble', '')
    parts = keibajo_date.split('_')
    
    # ç«¶é¦¬å ´åã‚’æ—¥æœ¬èªã«å¤‰æ›ï¼ˆæ—¢ã«æ—¥æœ¬èªã®å ´åˆã¯ãã®ã¾ã¾ï¼‰
    keibajo_code_to_jp = {
        'Saga': 'ä½è³€',
        'Ooi': 'å¤§äº•',
        'Kawasaki': 'å·å´',
        'Funabashi': 'èˆ¹æ©‹',
        'Urawa': 'æµ¦å’Œ',
        'Monbetsu': 'é–€åˆ¥',
        'Morioka': 'ç››å²¡',
        'Mizusawa': 'æ°´æ²¢',
        'Kanazawa': 'é‡‘æ²¢',
        'Kasamatsu': 'ç¬ æ¾',
        'Nagoya': 'åå¤å±‹',
        'Sonoda': 'åœ’ç”°',
        'Himeji': 'å§«è·¯',
        'Kochi': 'é«˜çŸ¥',
        # æ—¥æœ¬èªã®ã¾ã¾ã®å ´åˆ
        'ä½è³€': 'ä½è³€',
        'å¤§äº•': 'å¤§äº•',
        'å·å´': 'å·å´',
        'èˆ¹æ©‹': 'èˆ¹æ©‹',
        'æµ¦å’Œ': 'æµ¦å’Œ',
        'é–€åˆ¥': 'é–€åˆ¥',
        'ç››å²¡': 'ç››å²¡',
        'æ°´æ²¢': 'æ°´æ²¢',
        'é‡‘æ²¢': 'é‡‘æ²¢',
        'ç¬ æ¾': 'ç¬ æ¾',
        'åå¤å±‹': 'åå¤å±‹',
        'åœ’ç”°': 'åœ’ç”°',
        'å§«è·¯': 'å§«è·¯',
        'é«˜çŸ¥': 'é«˜çŸ¥'
    }
    
    keibajo_name_raw = parts[0] if len(parts) > 0 else "ç«¶é¦¬å ´"
    keibajo_name = keibajo_code_to_jp.get(keibajo_name_raw, keibajo_name_raw)
    date_str = parts[1] if len(parts) > 1 else ""
    
    # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›
    if len(date_str) == 8:
        year = date_str[:4]
        month = date_str[4:6]
        day = date_str[6:8]
        date_obj = datetime.strptime(date_str, '%Y%m%d')
        weekday_jp = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][date_obj.weekday()]
        formatted_date = f"{month}/{day}ï¼ˆ{weekday_jp}ï¼‰"
    else:
        formatted_date = date_str
    
    # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
    lines = []
    
    # ãƒ¬ãƒ¼ã‚¹ã”ã¨ã«å‡¦ç†
    race_count = 0
    for race_num in sorted(df['race_bango'].unique()):
        df_race = df[df['race_bango'] == race_num].copy()
        df_race = df_race.sort_values('final_rank')
        
        race_count += 1
        
        # ãƒ¬ãƒ¼ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼
        if race_count > 1:
            lines.append("")
            lines.append("=" * 50)
            lines.append("")
        
        lines.append(f"{formatted_date}{keibajo_name}{race_num}R")
        
        # ãƒ„ã‚¤ãƒ¼ãƒˆç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç”Ÿæˆ
        tweet_format = generate_tweet_format(df_race)
        if tweet_format:
            lines.append(tweet_format)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
    with open(output_txt, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))
    
    safe_print(f"[OK] Tweet format generation complete: {output_txt}")
    safe_print(f"  - Races: {race_count}R")
    safe_print(f"  - Lines: {len(lines)}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if len(sys.argv) != 3:
        safe_print("Usage: python generate_distribution_tweet.py <input_csv> <output_txt>")
        safe_print("Example: python generate_distribution_tweet.py data\\predictions\\phase5\\Saga_20260208_ensemble.csv predictions\\Saga_20260208_tweet.txt")
        sys.exit(1)
    
    input_csv = sys.argv[1]
    output_txt = sys.argv[2]
    
    if not Path(input_csv).exists():
        safe_print(f"[ERROR] Input file not found: {input_csv}")
        sys.exit(1)
    
    generate_distribution_text_tweet(input_csv, output_txt)


if __name__ == "__main__":
    main()
