#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
2026å¹´1æœˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ (çš„ä¸­ç‡ã®ã¿)
Phase 3ã®äºŒå€¤åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦2026å¹´1æœˆã®å®Ÿãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã€
çš„ä¸­ç‡ã‚’å°åˆ¥ã§åˆ†æã™ã‚‹ï¼ˆæ‰•æˆ»é‡‘ãƒ‡ãƒ¼ã‚¿ã¯ä½¿ç”¨ã—ãªã„ï¼‰
"""

import sys
import os
import psycopg2
import pandas as pd
import numpy as np
import lightgbm as lgb
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæƒ…å ±
DB_CONFIG = {
    'host': '127.0.0.1',
    'port': 5432,
    'database': 'pckeiba',
    'user': 'postgres',
    'password': 'postgres123'
}

# ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°
VENUE_MODELS = {
    '44': {'name': 'å¤§äº•', 'model': 'ooi_2023-2024_v3_model.txt'},
    '43': {'name': 'èˆ¹æ©‹', 'model': 'funabashi_2020-2025_v3_model.txt'},
    '45': {'name': 'å·å´', 'model': 'kawasaki_2020-2025_v3_model.txt'},
    '42': {'name': 'æµ¦å’Œ', 'model': 'urawa_2020-2025_v3_model.txt'},
    '48': {'name': 'åå¤å±‹', 'model': 'nagoya_2022-2025_v3_model.txt'},
    '50': {'name': 'åœ’ç”°', 'model': 'sonoda_2020-2025_v3_model.txt'},
    '47': {'name': 'ç¬ æ¾', 'model': 'kasamatsu_2020-2025_v3_model.txt'},
    '55': {'name': 'ä½è³€', 'model': 'saga_2020-2025_v3_model.txt'},
    '54': {'name': 'é«˜çŸ¥', 'model': 'kochi_2020-2025_v3_model.txt'},
    '51': {'name': 'å§«è·¯', 'model': 'himeji_2020-2025_v3_model.txt'},
}

def extract_2026_data(venue_code):
    """2026å¹´1æœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆæ‰•æˆ»é‡‘ãªã—ï¼‰"""
    
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        
        query = """
        SELECT 
            -- ãƒ¬ãƒ¼ã‚¹è­˜åˆ¥æƒ…å ±
            s.kaisai_nen,
            s.kaisai_tsukihi,
            s.keibajo_code,
            s.race_bango,
            s.umaban,
            
            -- çµæœï¼ˆæ­£è§£ãƒ©ãƒ™ãƒ«ï¼‰
            CASE WHEN CAST(s.kakutei_chakujun AS INTEGER) <= 3 THEN 1 ELSE 0 END as target,
            s.kakutei_chakujun,
            
            -- ãƒ¬ãƒ¼ã‚¹æƒ…å ±
            r.shusso_tosu,
            r.kyori,
            r.track_code,
            r.babajotai_code_shiba,
            r.babajotai_code_dirt,
            
            -- é¦¬æƒ…å ±
            s.seibetsu_code,
            s.barei,
            s.kishu_code,
            s.chokyoshi_code,
            s.futan_juryo,
            
            -- å‰èµ°æƒ…å ±ï¼ˆéå»5èµ°ï¼‰
            s.prev1_rank,
            s.prev1_time,
            s.prev1_last3f,
            s.prev1_weight,
            s.prev1_corner1,
            s.prev1_corner2,
            s.prev1_corner3,
            s.prev1_corner4,
            s.prev1_kyori,
            s.prev1_track,
            s.prev1_baba,
            
            s.prev2_rank,
            s.prev2_time,
            s.prev2_last3f,
            s.prev2_weight,
            s.prev2_corner1,
            s.prev2_corner2,
            s.prev2_corner3,
            s.prev2_corner4,
            s.prev2_kyori,
            s.prev2_track,
            s.prev2_baba,
            
            s.prev3_rank,
            s.prev3_time,
            s.prev3_last3f,
            s.prev3_weight,
            s.prev3_corner1,
            s.prev3_corner2,
            s.prev3_corner3,
            s.prev3_corner4,
            s.prev3_kyori,
            s.prev3_track,
            s.prev3_baba,
            
            s.prev4_rank,
            s.prev4_time,
            s.prev4_last3f,
            s.prev4_weight,
            s.prev4_corner1,
            s.prev4_corner2,
            s.prev4_corner3,
            s.prev4_corner4,
            s.prev4_kyori,
            s.prev4_track,
            s.prev4_baba,
            
            s.prev5_rank,
            s.prev5_time,
            s.prev5_last3f,
            s.prev5_weight,
            s.prev5_corner1,
            s.prev5_corner2,
            s.prev5_corner3,
            s.prev5_corner4,
            s.prev5_kyori,
            s.prev5_track,
            s.prev5_baba,
            
            s.ketto_toroku_bango
            
        FROM nvd_se s
        LEFT JOIN nvd_ra r ON 
            r.kaisai_nen = s.kaisai_nen AND
            r.kaisai_tsukihi = s.kaisai_tsukihi AND
            r.keibajo_code = s.keibajo_code AND
            r.race_bango = s.race_bango
        WHERE s.kaisai_nen = '2026'
        AND s.keibajo_code = %s
        AND s.kaisai_tsukihi >= '0101' 
        AND s.kaisai_tsukihi <= '0131'
        AND s.kakutei_chakujun IS NOT NULL
        AND s.kakutei_chakujun != '0'
        ORDER BY s.kaisai_tsukihi, s.race_bango, s.umaban
        """
        
        df = pd.read_sql_query(query, conn, params=(venue_code,))
        conn.close()
        
        return df
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return None

def load_model(model_path):
    """LightGBMãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
    
    try:
        if not os.path.exists(model_path):
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
            return None
            
        model = lgb.Booster(model_file=model_path)
        return model
        
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def preprocess_features(df):
    """ç‰¹å¾´é‡ã®å‰å‡¦ç†"""
    
    # è­˜åˆ¥æƒ…å ±ã¨æ­£è§£ãƒ©ãƒ™ãƒ«ã‚’ä¿å­˜
    id_cols = ['kaisai_nen', 'kaisai_tsukihi', 'keibajo_code', 'race_bango', 
               'umaban', 'target', 'kakutei_chakujun']
    
    df_id = df[id_cols].copy()
    
    # ç‰¹å¾´é‡ã®ã¿æŠ½å‡º
    feature_cols = [col for col in df.columns if col not in id_cols]
    X = df[feature_cols].copy()
    
    # æ•°å€¤å‹ã«å¤‰æ›
    for col in X.columns:
        X[col] = pd.to_numeric(X[col], errors='coerce')
    
    # æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ
    X = X.fillna(X.mean())
    
    # ç„¡é™å¤§ã‚’0ã«ç½®æ›
    X = X.replace([np.inf, -np.inf], 0)
    
    return X, df_id

def assign_mark(prob):
    """ç¢ºç‡ã«åŸºã¥ã„ã¦å°ã‚’å‰²ã‚Šå½“ã¦"""
    
    if prob >= 0.7:
        return 'â—'
    elif prob >= 0.5:
        return 'â—‹'
    elif prob >= 0.35:
        return 'â–²'
    elif prob >= 0.2:
        return 'â–³'
    else:
        return 'Ã—'

def calculate_hitrate(df_results):
    """çš„ä¸­ç‡ã®ã¿ã‚’è¨ˆç®—ï¼ˆå›åç‡ã¯è¨ˆç®—ã—ãªã„ï¼‰"""
    
    summary = []
    
    # å…¨ä½“
    total_races = len(df_results)
    total_hits = (df_results['target'] == 1).sum()
    hitrate = total_hits / total_races * 100 if total_races > 0 else 0
    
    summary.append({
        'category': 'å…¨ä½“',
        'count': total_races,
        'hits': total_hits,
        'hitrate': hitrate
    })
    
    # å˜å‹ï¼ˆâ—æœ¬å‘½ã®ã¿ï¼‰
    honmei = df_results[df_results['mark'] == 'â—']
    if len(honmei) > 0:
        honmei_hits = (honmei['target'] == 1).sum()
        honmei_hitrate = honmei_hits / len(honmei) * 100
        
        summary.append({
            'category': 'å˜å‹ï¼ˆâ—æœ¬å‘½ã®ã¿ï¼‰',
            'count': len(honmei),
            'hits': honmei_hits,
            'hitrate': honmei_hitrate
        })
    
    # è¤‡å‹ï¼ˆâ—â—‹â–²ï¼‰
    fukusho_marks = df_results[df_results['mark'].isin(['â—', 'â—‹', 'â–²'])]
    if len(fukusho_marks) > 0:
        fukusho_hits = (fukusho_marks['target'] == 1).sum()
        fukusho_hitrate = fukusho_hits / len(fukusho_marks) * 100
        
        summary.append({
            'category': 'è¤‡å‹ï¼ˆâ—â—‹â–²ï¼‰',
            'count': len(fukusho_marks),
            'hits': fukusho_hits,
            'hitrate': fukusho_hitrate
        })
    
    # å°åˆ¥é›†è¨ˆ
    for mark in ['â—', 'â—‹', 'â–²', 'â–³', 'Ã—']:
        mark_df = df_results[df_results['mark'] == mark]
        if len(mark_df) > 0:
            mark_hits = (mark_df['target'] == 1).sum()
            mark_hitrate = mark_hits / len(mark_df) * 100
            
            summary.append({
                'category': f'å°åˆ¥: {mark}',
                'count': len(mark_df),
                'hits': mark_hits,
                'hitrate': mark_hitrate
            })
    
    return pd.DataFrame(summary)

def simulate_venue(venue_code, venue_name, model_path):
    """ç«¶é¦¬å ´åˆ¥ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
    
    print(f"\n{'='*80}")
    print(f"ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ: {venue_name} (ã‚³ãƒ¼ãƒ‰: {venue_code})")
    print(f"{'='*80}")
    
    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­...")
    df = extract_2026_data(venue_code)
    
    if df is None or len(df) == 0:
        print(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return None, None
    
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df):,} ä»¶")
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­: {model_path}")
    model = load_model(model_path)
    
    if model is None:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
        return None, None
    
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
    
    # ç‰¹å¾´é‡å‰å‡¦ç†
    print(f"âš™ï¸  ç‰¹å¾´é‡å‰å‡¦ç†ä¸­...")
    X, df_id = preprocess_features(df)
    
    # äºˆæ¸¬å®Ÿè¡Œ
    print(f"ğŸ”® äºˆæ¸¬å®Ÿè¡Œä¸­...")
    y_pred_prob = model.predict(X, num_iteration=model.best_iteration)
    
    # çµæœçµåˆ
    df_results = df_id.copy()
    df_results['prob'] = y_pred_prob
    df_results['mark'] = df_results['prob'].apply(assign_mark)
    df_results['venue_name'] = venue_name
    
    # çš„ä¸­ç‡è¨ˆç®—
    print(f"ğŸ“ˆ çš„ä¸­ç‡è¨ˆç®—ä¸­...")
    df_summary = calculate_hitrate(df_results)
    df_summary['venue_name'] = venue_name
    df_summary['venue_code'] = venue_code
    
    print(f"âœ… ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {venue_name}")
    
    return df_results, df_summary

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    
    print("=" * 80)
    print("2026å¹´1æœˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ (çš„ä¸­ç‡ã®ã¿)")
    print("=" * 80)
    print(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"å¯¾è±¡æœŸé–“: 2026-01-01 ï½ 2026-01-31")
    print(f"å¯¾è±¡ç«¶é¦¬å ´: 10ç«¶é¦¬å ´")
    print("=" * 80)
    
    all_results = []
    all_summaries = []
    
    # å„ç«¶é¦¬å ´ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    for venue_code, venue_info in VENUE_MODELS.items():
        venue_name = venue_info['name']
        model_path = venue_info['model']
        
        df_results, df_summary = simulate_venue(venue_code, venue_name, model_path)
        
        if df_results is not None:
            all_results.append(df_results)
        
        if df_summary is not None:
            all_summaries.append(df_summary)
    
    # çµæœã‚’çµåˆ
    if len(all_results) > 0:
        df_all_results = pd.concat(all_results, ignore_index=True)
        df_all_summaries = pd.concat(all_summaries, ignore_index=True)
        
        # CSVå‡ºåŠ›
        output_results = 'simulation_2026_hitrate_results.csv'
        output_summary = 'simulation_2026_hitrate_summary.csv'
        
        df_all_results.to_csv(output_results, index=False, encoding='utf-8-sig')
        df_all_summaries.to_csv(output_summary, index=False, encoding='utf-8-sig')
        
        print(f"\n{'='*80}")
        print(f"âœ… ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
        print(f"{'='*80}")
        print(f"ğŸ“„ äºˆæ¸¬çµæœ: {output_results}")
        print(f"ğŸ“„ ã‚µãƒãƒªãƒ¼: {output_summary}")
        print(f"{'='*80}")
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        generate_text_report(df_all_summaries, df_all_results)
        
    else:
        print("\nâŒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

def generate_text_report(df_summary, df_results):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    
    report = []
    report.append("=" * 80)
    report.append("2026å¹´1-2æœˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœãƒ¬ãƒãƒ¼ãƒˆ (çš„ä¸­ç‡ã®ã¿)")
    report.append("=" * 80)
    report.append(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"å¯¾è±¡æœŸé–“: 2026-01-01 ï½ 2026-02-03")
    report.append(f"å¯¾è±¡ç«¶é¦¬å ´: {len(VENUE_MODELS)}ç«¶é¦¬å ´")
    report.append(f"ç·ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df_results):,} ä»¶")
    report.append("=" * 80)
    report.append("")
    
    # ç«¶é¦¬å ´åˆ¥ã‚µãƒãƒªãƒ¼
    report.append("ã€ç«¶é¦¬å ´åˆ¥ã‚µãƒãƒªãƒ¼ã€‘")
    report.append("")
    
    for venue_code, venue_info in VENUE_MODELS.items():
        venue_name = venue_info['name']
        venue_summary = df_summary[df_summary['venue_name'] == venue_name]
        
        if len(venue_summary) > 0:
            report.append(f"â–  {venue_name}")
            
            for _, row in venue_summary.iterrows():
                if row['category'] == 'å…¨ä½“':
                    report.append(f"  ç·ä»¶æ•°: {int(row['count']):,} ä»¶")
                    report.append(f"  çš„ä¸­æ•°: {int(row['hits']):,} ä»¶")
                    report.append(f"  çš„ä¸­ç‡: {row['hitrate']:.2f}%")
                elif row['category'] == 'å˜å‹ï¼ˆâ—æœ¬å‘½ã®ã¿ï¼‰':
                    report.append(f"  å˜å‹â—: {int(row['count']):,}ç‚¹ / çš„ä¸­ç‡ {row['hitrate']:.2f}%")
                elif row['category'] == 'è¤‡å‹ï¼ˆâ—â—‹â–²ï¼‰':
                    report.append(f"  è¤‡å‹â—â—‹â–²: {int(row['count']):,}ç‚¹ / çš„ä¸­ç‡ {row['hitrate']:.2f}%")
            
            report.append("")
    
    # å…¨ä½“é›†è¨ˆ
    report.append("=" * 80)
    report.append("ã€å…¨ä½“é›†è¨ˆã€‘")
    report.append("")
    
    total_count = len(df_results)
    total_hits = (df_results['target'] == 1).sum()
    total_hitrate = total_hits / total_count * 100 if total_count > 0 else 0
    
    report.append(f"ç·ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {total_count:,} ä»¶")
    report.append(f"ç·çš„ä¸­æ•°: {total_hits:,} ä»¶")
    report.append(f"ç·çš„ä¸­ç‡: {total_hitrate:.2f}%")
    report.append("")
    
    # å°åˆ¥é›†è¨ˆ
    report.append("ã€å°åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘")
    report.append("")
    
    for mark in ['â—', 'â—‹', 'â–²', 'â–³', 'Ã—']:
        mark_df = df_results[df_results['mark'] == mark]
        if len(mark_df) > 0:
            mark_hits = (mark_df['target'] == 1).sum()
            mark_hitrate = mark_hits / len(mark_df) * 100
            report.append(f"{mark}: {len(mark_df):,}ä»¶ / çš„ä¸­ {mark_hits:,}ä»¶ / çš„ä¸­ç‡ {mark_hitrate:.2f}%")
    
    report.append("")
    report.append("=" * 80)
    report.append("æ³¨: å›åç‡ã®è¨ˆç®—ã¯æ¬¡å›å¯¾å¿œäºˆå®šã§ã™")
    report.append("=" * 80)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    output_txt = 'simulation_2026_hitrate_summary.txt'
    with open(output_txt, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    print(f"ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ: {output_txt}")

if __name__ == '__main__':
    main()
