# ğŸ‡ JRAç‰ˆAIäºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ç”¨ï¼šæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

**ä½œæˆæ—¥**: 2026å¹´02æœˆ14æ—¥  
**å¯¾è±¡**: æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã®JRAç‰ˆé–‹ç™º  
**å…ƒãƒªãƒã‚¸ãƒˆãƒª**: https://github.com/aka209859-max/anonymous-keiba-ai

---

## ğŸ“‹ ç›®æ¬¡

1. [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“æ¦‚è¦](#1-ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“æ¦‚è¦)
2. [Phase 0: ãƒ‡ãƒ¼ã‚¿å–å¾—ã®å®Ÿè£…ä¾‹](#2-phase-0-ãƒ‡ãƒ¼ã‚¿å–å¾—ã®å®Ÿè£…ä¾‹)
3. [Phase 1: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å®Ÿè£…ä¾‹](#3-phase-1-ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å®Ÿè£…ä¾‹)
4. [Phase 3: äºŒå€¤åˆ†é¡ã®å®Ÿè£…ä¾‹](#4-phase-3-äºŒå€¤åˆ†é¡ã®å®Ÿè£…ä¾‹)
5. [Phase 5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆã®å®Ÿè£…ä¾‹](#5-phase-5-ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆã®å®Ÿè£…ä¾‹)
6. [Phase 6: è²·ã„ç›®ç”Ÿæˆã®å®Ÿè£…ä¾‹](#6-phase-6-è²·ã„ç›®ç”Ÿæˆã®å®Ÿè£…ä¾‹)
7. [JRAç‰ˆã§ã®å¤‰æ›´ãƒã‚¤ãƒ³ãƒˆ](#7-jraç‰ˆã§ã®å¤‰æ›´ãƒã‚¤ãƒ³ãƒˆ)
8. [JRA-VAN + JRDB äºŒæœ¬ç«‹ã¦ãƒ‡ãƒ¼ã‚¿å–å¾—æˆ¦ç•¥](#8-jra-van--jrdb-äºŒæœ¬ç«‹ã¦ãƒ‡ãƒ¼ã‚¿å–å¾—æˆ¦ç•¥)

---

## 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“æ¦‚è¦

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
anonymous-keiba-ai/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ phase0_data_acquisition/       # PC-KEIBA PostgreSQL ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
â”‚   â”œâ”€â”€ phase1_feature_engineering/    # 50ç‰¹å¾´é‡ç”Ÿæˆ
â”‚   â”œâ”€â”€ phase3_binary/                 # å‡ºèµ°/éå‡ºèµ°åˆ¤å®šï¼ˆLightGBMï¼‰
â”‚   â”œâ”€â”€ phase4_ranking/                # ç€é †äºˆæ¸¬ï¼ˆLightGBM Rankerï¼‰
â”‚   â”œâ”€â”€ phase4_regression/             # ã‚¿ã‚¤ãƒ äºˆæ¸¬ï¼ˆLightGBM Regressorï¼‰
â”‚   â”œâ”€â”€ phase5_ensemble/               # é‡ã¿ä»˜ã‘çµ±åˆï¼ˆ30/50/20%ï¼‰
â”‚   â”œâ”€â”€ phase6_betting/                # Note/ãƒ–ãƒƒã‚«ãƒ¼ã‚º/Twitterç”¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
â”‚   â”œâ”€â”€ phase7_feature_selection/      # Greedy Boruta
â”‚   â”œâ”€â”€ phase8_auto_tuning/            # Optuna
â”‚   â”œâ”€â”€ phase9_betting_strategy/       # KellyåŸºæº–
â”‚   â””â”€â”€ phase10_backtest/              # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ binary/                        # 14ç«¶é¦¬å ´åˆ¥ãƒ¢ãƒ‡ãƒ«ï¼ˆ.txtå½¢å¼ï¼‰
â”‚   â”œâ”€â”€ ranking/
â”‚   â””â”€â”€ regression/
â””â”€â”€ data/
    â”œâ”€â”€ raw/                           # {å¹´}/{æœˆ}/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_raw.csv
    â”œâ”€â”€ features/                      # {å¹´}/{æœˆ}/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_features.csv
    â””â”€â”€ predictions/                   # phase3ã€œphase6ã®å‡ºåŠ›
```

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³

```
[Phase 0] ãƒ‡ãƒ¼ã‚¿å–å¾—
  â†“ PC-KEIBA PostgreSQL ã‚¯ã‚¨ãƒª
  â†“ å‡ºåŠ›: data/raw/2026/02/èˆ¹æ©‹_20260214_raw.csv (50ã‚«ãƒ©ãƒ )
  
[Phase 1] ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
  â†“ raw CSV â†’ 50ç‰¹å¾´é‡ç”Ÿæˆ
  â†“ å‡ºåŠ›: data/features/2026/02/èˆ¹æ©‹_20260214_features.csv (50ã‚«ãƒ©ãƒ )
  
[Phase 3] äºŒå€¤åˆ†é¡äºˆæ¸¬
  â†“ LightGBM (models/binary/funabashi_2020-2025_v3_model.txt)
  â†“ å‡ºåŠ›: data/predictions/phase3/temp_20260214_phase3_binary.csv
  â†“ ã‚«ãƒ©ãƒ : race_id, umaban, binary_probability, predicted_class
  
[Phase 4-1] ãƒ©ãƒ³ã‚­ãƒ³ã‚°äºˆæ¸¬
  â†“ LightGBM Ranker (models/ranking/...)
  â†“ å‡ºåŠ›: data/predictions/phase4_ranking/temp_20260214_phase4_ranking.csv
  â†“ ã‚«ãƒ©ãƒ : race_id, umaban, ranking_score, predicted_rank
  
[Phase 4-2] å›å¸°äºˆæ¸¬
  â†“ LightGBM Regressor (models/regression/...)
  â†“ å‡ºåŠ›: data/predictions/phase4_regression/temp_20260214_phase4_regression.csv
  â†“ ã‚«ãƒ©ãƒ : race_id, umaban, predicted_time, time_rank
  
[Phase 5] ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ
  â†“ é‡ã¿: Binary 30%, Ranking 50%, Regression 20%
  â†“ å‡ºåŠ›: data/predictions/phase5/temp_20260214_ensemble.csv
  â†“ ã‚«ãƒ©ãƒ : race_id, kaisai_nen, kaisai_tsukihi, keibajo_code, race_bango,
  â†“        ketto_toroku_bango, umaban, ensemble_score, final_rank,
  â†“        binary_probability, predicted_class, ranking_score, predicted_rank,
  â†“        predicted_time, time_rank
  
[Phase 6] é…ä¿¡ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
  â†“ ensemble CSV â†’ è²·ã„ç›®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
  â†“ å‡ºåŠ›: predictions/èˆ¹æ©‹_20260214_note.txt
  â†“       predictions/èˆ¹æ©‹_20260214_bookers.txt
  â†“       predictions/èˆ¹æ©‹_20260214_tweet.txt
```

---

## 2. Phase 0: ãƒ‡ãƒ¼ã‚¿å–å¾—ã®å®Ÿè£…ä¾‹

### 2.1 ä¸»è¦æ©Ÿèƒ½

**ãƒ•ã‚¡ã‚¤ãƒ«**: `scripts/phase0_data_acquisition/extract_race_data.py`

**æ©Ÿèƒ½æ¦‚è¦**:
- PC-KEIBA PostgreSQL ã‹ã‚‰éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
- ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ã¨æ—¥ä»˜ã‚’æŒ‡å®š
- å‡ºåŠ›: CSVå½¢å¼ï¼ˆ50ã‚«ãƒ©ãƒ ï¼‰

### 2.2 ã‚³ã‚¢å®Ÿè£…ï¼ˆç°¡ç•¥ç‰ˆï¼‰

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 0: ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆåœ°æ–¹ç«¶é¦¬ç‰ˆï¼‰
PC-KEIBA PostgreSQL ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
"""

import psycopg2
import pandas as pd
import argparse
from pathlib import Path

# ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
VENUE_CODES = {
    '30': 'é–€åˆ¥', '35': 'ç››å²¡', '36': 'æ°´æ²¢',
    '42': 'æµ¦å’Œ', '43': 'èˆ¹æ©‹', '44': 'å¤§äº•', '45': 'å·å´',
    '46': 'é‡‘æ²¢', '47': 'ç¬ æ¾', '48': 'åå¤å±‹',
    '50': 'åœ’ç”°', '51': 'å§«è·¯', '54': 'é«˜çŸ¥', '55': 'ä½è³€'
}

def connect_to_pckeiba():
    """PC-KEIBA PostgreSQL ã«æ¥ç¶š"""
    conn = psycopg2.connect(
        host="localhost",
        port=5432,
        database="pckeiba",
        user="pckeiba_user",
        password="your_password"
    )
    return conn

def extract_race_data(keibajo_code, target_date):
    """
    æŒ‡å®šã•ã‚ŒãŸç«¶é¦¬å ´ãƒ»æ—¥ä»˜ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Args:
        keibajo_code: ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹: '43' = èˆ¹æ©‹ï¼‰
        target_date: å¯¾è±¡æ—¥ä»˜ï¼ˆä¾‹: '2026-02-14'ï¼‰
    
    Returns:
        pd.DataFrame: ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
    """
    conn = connect_to_pckeiba()
    
    # SQL ã‚¯ã‚¨ãƒªï¼ˆå®Ÿéš›ã®PC-KEIBAãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
    query = f"""
    SELECT 
        kaisai_nen,
        kaisai_tsukihi,
        keibajo_code,
        race_bango,
        ketto_toroku_bango,
        umaban,
        bamei,
        kakutei_chakujun,
        jockey_code,
        jockey_name,
        trainer_code,
        trainer_name,
        umajirushi_bango,
        sei,
        barei,
        kinryo,
        bataiju,
        zougen,
        zogen_sign,
        -- ... ä»–ã®50ã‚«ãƒ©ãƒ 
    FROM 
        n_uma
    WHERE 
        keibajo_code = '{keibajo_code}'
        AND kaisai_tsukihi = '{target_date.replace("-", "")}'
    ORDER BY 
        race_bango, umaban
    """
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df)}ä»¶")
    return df

def save_to_csv(df, keibajo_code, target_date, output_dir="data/raw"):
    """CSVå½¢å¼ã§ä¿å­˜"""
    venue_name = VENUE_CODES.get(keibajo_code, 'unknown')
    year = target_date[:4]
    month = target_date[5:7]
    date_short = target_date.replace("-", "")
    
    output_path = Path(output_dir) / year / month
    output_path.mkdir(parents=True, exist_ok=True)
    
    output_file = output_path / f"{venue_name}_{date_short}_raw.csv"
    df.to_csv(output_file, index=False, encoding='shift-jis')
    
    print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {output_file}")
    return str(output_file)

def main():
    parser = argparse.ArgumentParser(description='Phase 0: ãƒ‡ãƒ¼ã‚¿å–å¾—')
    parser.add_argument('--keibajo', type=str, required=True, help='ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹: 43ï¼‰')
    parser.add_argument('--date', type=str, required=True, help='æ—¥ä»˜ï¼ˆä¾‹: 2026-02-14ï¼‰')
    args = parser.parse_args()
    
    print("="*80)
    print("Phase 0: ãƒ‡ãƒ¼ã‚¿å–å¾—")
    print("="*80)
    print(f"ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰: {args.keibajo}")
    print(f"å¯¾è±¡æ—¥ä»˜: {args.date}")
    
    df = extract_race_data(args.keibajo, args.date)
    save_to_csv(df, args.keibajo, args.date)
    
    print("âœ… Phase 0 å®Œäº†")

if __name__ == "__main__":
    main()
```

### 2.3 é‡è¦ãªã‚«ãƒ©ãƒ ï¼ˆ50ã‚«ãƒ©ãƒ ã®ä¾‹ï¼‰

```python
# PC-KEIBA ã®ä¸»è¦ã‚«ãƒ©ãƒ 
COLUMNS = [
    'kaisai_nen',           # é–‹å‚¬å¹´
    'kaisai_tsukihi',       # é–‹å‚¬æœˆæ—¥ï¼ˆYYYYMMDDï¼‰
    'keibajo_code',         # ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰
    'race_bango',           # ãƒ¬ãƒ¼ã‚¹ç•ªå·ï¼ˆ1ã€œ12ï¼‰
    'ketto_toroku_bango',   # è¡€çµ±ç™»éŒ²ç•ªå·
    'umaban',               # é¦¬ç•ª
    'bamei',                # é¦¬å
    'kakutei_chakujun',     # ç¢ºå®šç€é †
    'jockey_code',          # é¨æ‰‹ã‚³ãƒ¼ãƒ‰
    'jockey_name',          # é¨æ‰‹å
    'trainer_code',         # èª¿æ•™å¸«ã‚³ãƒ¼ãƒ‰
    'trainer_name',         # èª¿æ•™å¸«å
    'barei',                # é¦¬é½¢
    'kinryo',               # æ–¤é‡
    'bataiju',              # é¦¬ä½“é‡
    'zougen',               # å¢—æ¸›
    'wakuban',              # æ ç•ª
    'seibetsu',             # æ€§åˆ¥ï¼ˆç‰¡/ç‰/ã‚»ï¼‰
    'æ¯›è‰²',
    'çˆ¶é¦¬å',
    'æ¯é¦¬å',
    # ... ä»–40ã‚«ãƒ©ãƒ 
]
```

---

## 3. Phase 1: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å®Ÿè£…ä¾‹

### 3.1 ä¸»è¦æ©Ÿèƒ½

**ãƒ•ã‚¡ã‚¤ãƒ«**: `scripts/phase1_feature_engineering/prepare_features_safe.py`

**æ©Ÿèƒ½æ¦‚è¦**:
- raw CSV ã‹ã‚‰50ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
- éå»3èµ°ã®ç€é †ã€é¨æ‰‹æˆç¸¾ã€é¦¬ä½“é‡å¢—æ¸›ãªã©
- æ¬ æå€¤å‡¦ç†ï¼ˆå¹³å‡å€¤/0åŸ‹ã‚ï¼‰

### 3.2 ã‚³ã‚¢å®Ÿè£…ï¼ˆç°¡ç•¥ç‰ˆï¼‰

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 1: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆåœ°æ–¹ç«¶é¦¬ç‰ˆï¼‰
"""

import pandas as pd
import numpy as np
from pathlib import Path

def load_raw_data(raw_csv_path):
    """raw CSV ã‚’èª­ã¿è¾¼ã¿"""
    try:
        df = pd.read_csv(raw_csv_path, encoding='shift-jis')
    except:
        df = pd.read_csv(raw_csv_path, encoding='utf-8')
    
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}ä»¶")
    return df

def create_basic_features(df):
    """åŸºæœ¬ç‰¹å¾´é‡ã‚’ä½œæˆ"""
    df_features = df.copy()
    
    # 1. é¦¬ç•ªï¼ˆæ•°å€¤åŒ–ï¼‰
    df_features['umaban_num'] = df['umaban'].astype(int)
    
    # 2. æ ç•ªï¼ˆæ•°å€¤åŒ–ï¼‰
    df_features['wakuban_num'] = df['wakuban'].astype(int) if 'wakuban' in df.columns else 0
    
    # 3. æ–¤é‡ï¼ˆæ•°å€¤åŒ–ï¼‰
    df_features['kinryo_num'] = df['kinryo'].astype(float) if 'kinryo' in df.columns else 0.0
    
    # 4. é¦¬é½¢ï¼ˆæ•°å€¤åŒ–ï¼‰
    df_features['barei_num'] = df['barei'].astype(int) if 'barei' in df.columns else 0
    
    # 5. é¦¬ä½“é‡ï¼ˆæ•°å€¤åŒ–ï¼‰
    df_features['bataiju_num'] = df['bataiju'].astype(float) if 'bataiju' in df.columns else 0.0
    
    # 6. é¦¬ä½“é‡å¢—æ¸›ï¼ˆæ•°å€¤åŒ–ï¼‰
    df_features['zougen_num'] = df['zougen'].astype(float) if 'zougen' in df.columns else 0.0
    
    # 7. æ€§åˆ¥ï¼ˆOne-Hotï¼‰
    if 'seibetsu' in df.columns:
        df_features['sei_male'] = (df['seibetsu'] == 'ç‰¡').astype(int)
        df_features['sei_female'] = (df['seibetsu'] == 'ç‰').astype(int)
        df_features['sei_gelding'] = (df['seibetsu'] == 'ã‚»').astype(int)
    else:
        df_features['sei_male'] = 0
        df_features['sei_female'] = 0
        df_features['sei_gelding'] = 0
    
    return df_features

def create_past_performance_features(df):
    """éå»æˆç¸¾ç‰¹å¾´é‡ã‚’ä½œæˆ"""
    # æ³¨: å®Ÿéš›ã«ã¯PC-KEIBAã®historyãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—
    # ã“ã“ã§ã¯ç°¡ç•¥åŒ–ã®ãŸã‚ãƒ€ãƒŸãƒ¼å®Ÿè£…
    
    df['prev1_rank'] = 0  # å‰èµ°ç€é †
    df['prev2_rank'] = 0  # å‰ã€…èµ°ç€é †
    df['prev3_rank'] = 0  # 3èµ°å‰ç€é †
    
    df['prev1_time'] = 0.0  # å‰èµ°ã‚¿ã‚¤ãƒ 
    df['prev2_time'] = 0.0
    df['prev3_time'] = 0.0
    
    df['prev1_class'] = 0  # å‰èµ°ã‚¯ãƒ©ã‚¹
    df['prev2_class'] = 0
    df['prev3_class'] = 0
    
    # å‹ç‡ãƒ»é€£å¯¾ç‡
    df['win_rate'] = 0.0
    df['place_rate'] = 0.0
    df['show_rate'] = 0.0
    
    return df

def create_jockey_trainer_features(df):
    """é¨æ‰‹ãƒ»èª¿æ•™å¸«ç‰¹å¾´é‡ã‚’ä½œæˆ"""
    # æ³¨: å®Ÿéš›ã«ã¯PC-KEIBAã®é›†è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—
    
    df['jockey_win_rate'] = 0.0
    df['jockey_place_rate'] = 0.0
    df['jockey_total_races'] = 0
    
    df['trainer_win_rate'] = 0.0
    df['trainer_place_rate'] = 0.0
    df['trainer_total_races'] = 0
    
    return df

def create_speed_rating(df):
    """ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°ã‚’è¨ˆç®—"""
    # ç°¡æ˜“çš„ãªå®Ÿè£…
    df['speed_rating'] = 0.0
    
    return df

def fill_missing_values(df):
    """æ¬ æå€¤å‡¦ç†"""
    # æ•°å€¤ã‚«ãƒ©ãƒ ã¯å¹³å‡å€¤ã¾ãŸã¯0ã§åŸ‹ã‚ã‚‹
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    for col in numeric_cols:
        if df[col].isna().sum() > 0:
            mean_val = df[col].mean()
            if np.isnan(mean_val):
                df[col] = df[col].fillna(0)
            else:
                df[col] = df[col].fillna(mean_val)
    
    # æ–‡å­—åˆ—ã‚«ãƒ©ãƒ ã¯ç©ºæ–‡å­—ã§åŸ‹ã‚ã‚‹
    string_cols = df.select_dtypes(include=[object]).columns
    for col in string_cols:
        df[col] = df[col].fillna('')
    
    return df

def save_features_csv(df, venue_name, date_short, output_dir="data/features"):
    """ç‰¹å¾´é‡CSVã‚’ä¿å­˜"""
    year = date_short[:4]
    month = date_short[4:6]
    
    output_path = Path(output_dir) / year / month
    output_path.mkdir(parents=True, exist_ok=True)
    
    output_file = output_path / f"{venue_name}_{date_short}_features.csv"
    df.to_csv(output_file, index=False, encoding='shift-jis')
    
    print(f"ğŸ’¾ ç‰¹å¾´é‡CSVä¿å­˜: {output_file}")
    return str(output_file)

def main():
    import sys
    
    if len(sys.argv) < 5:
        print("ä½¿ç”¨æ³•: python prepare_features_safe.py [ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰] [å¹´] [æœˆ] [æ—¥ä»˜çŸ­ç¸®å½¢]")
        sys.exit(1)
    
    keibajo_code = sys.argv[1]
    year = sys.argv[2]
    month = sys.argv[3]
    date_short = sys.argv[4]
    
    # ç«¶é¦¬å ´åå–å¾—
    venue_map = {
        '30': 'é–€åˆ¥', '35': 'ç››å²¡', '36': 'æ°´æ²¢',
        '42': 'æµ¦å’Œ', '43': 'èˆ¹æ©‹', '44': 'å¤§äº•', '45': 'å·å´',
        '46': 'é‡‘æ²¢', '47': 'ç¬ æ¾', '48': 'åå¤å±‹',
        '50': 'åœ’ç”°', '51': 'å§«è·¯', '54': 'é«˜çŸ¥', '55': 'ä½è³€'
    }
    venue_name = venue_map.get(keibajo_code, 'unknown')
    
    # raw CSV ãƒ‘ã‚¹
    raw_csv = f"data/raw/{year}/{month}/{venue_name}_{date_short}_raw.csv"
    
    print("="*80)
    print("Phase 1: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
    print("="*80)
    
    df = load_raw_data(raw_csv)
    
    df = create_basic_features(df)
    df = create_past_performance_features(df)
    df = create_jockey_trainer_features(df)
    df = create_speed_rating(df)
    df = fill_missing_values(df)
    
    save_features_csv(df, venue_name, date_short)
    
    print("âœ… Phase 1 å®Œäº†")

if __name__ == "__main__":
    main()
```

### 3.3 ç”Ÿæˆã•ã‚Œã‚‹ç‰¹å¾´é‡ä¸€è¦§ï¼ˆ50å€‹ï¼‰

```python
FEATURE_COLUMNS = [
    # åŸºæœ¬æƒ…å ±
    'umaban_num', 'wakuban_num', 'kinryo_num', 'barei_num',
    'bataiju_num', 'zougen_num',
    'sei_male', 'sei_female', 'sei_gelding',
    
    # éå»æˆç¸¾
    'prev1_rank', 'prev2_rank', 'prev3_rank',
    'prev1_time', 'prev2_time', 'prev3_time',
    'prev1_class', 'prev2_class', 'prev3_class',
    'win_rate', 'place_rate', 'show_rate',
    
    # é¨æ‰‹
    'jockey_win_rate', 'jockey_place_rate', 'jockey_total_races',
    
    # èª¿æ•™å¸«
    'trainer_win_rate', 'trainer_place_rate', 'trainer_total_races',
    
    # ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°
    'speed_rating',
    
    # ... ä»–20ç‰¹å¾´é‡
]
```

---

## 4. Phase 3: äºŒå€¤åˆ†é¡ã®å®Ÿè£…ä¾‹

### 4.1 ä¸»è¦æ©Ÿèƒ½

**ãƒ•ã‚¡ã‚¤ãƒ«**: `scripts/phase3_binary/predict_phase3_inference.py`

**æ©Ÿèƒ½æ¦‚è¦**:
- LightGBMãƒ¢ãƒ‡ãƒ«ã§å‡ºèµ°/éå‡ºèµ°ã‚’äºˆæ¸¬
- ç«¶é¦¬å ´åˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
- å‡ºåŠ›: binary_probability, predicted_class

### 4.2 ã‚³ã‚¢å®Ÿè£…ï¼ˆç°¡ç•¥ç‰ˆï¼‰

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 3: äºŒå€¤åˆ†é¡äºˆæ¸¬ï¼ˆåœ°æ–¹ç«¶é¦¬ç‰ˆï¼‰
"""

import pandas as pd
import lightgbm as lgb
from pathlib import Path

def load_features_csv(features_csv_path):
    """ç‰¹å¾´é‡CSVã‚’èª­ã¿è¾¼ã¿"""
    try:
        df = pd.read_csv(features_csv_path, encoding='shift-jis')
    except:
        df = pd.read_csv(features_csv_path, encoding='utf-8')
    
    print(f"âœ… ç‰¹å¾´é‡èª­ã¿è¾¼ã¿: {len(df)}ä»¶, {len(df.columns)}ã‚«ãƒ©ãƒ ")
    return df

def load_lightgbm_model(model_path):
    """LightGBMãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    model = lgb.Booster(model_file=model_path)
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {model_path}")
    return model

def predict_binary(df, model, feature_columns):
    """äºŒå€¤åˆ†é¡äºˆæ¸¬"""
    X = df[feature_columns]
    
    # äºˆæ¸¬ï¼ˆç¢ºç‡ï¼‰
    y_pred_proba = model.predict(X)
    
    # äºŒå€¤åˆ†é¡ï¼ˆé–¾å€¤0.5ï¼‰
    y_pred_class = (y_pred_proba >= 0.5).astype(int)
    
    df['binary_probability'] = y_pred_proba
    df['predicted_class'] = y_pred_class
    
    print(f"âœ… äºˆæ¸¬å®Œäº†")
    print(f"  - å¹³å‡ç¢ºç‡: {y_pred_proba.mean():.4f}")
    print(f"  - å‡ºèµ°äºˆæ¸¬æ•°: {y_pred_class.sum()}/{len(y_pred_class)} ({y_pred_class.sum()/len(y_pred_class)*100:.1f}%)")
    
    return df

def save_binary_csv(df, output_path):
    """äºˆæ¸¬çµæœã‚’ä¿å­˜"""
    output_cols = [
        'race_id', 'kaisai_nen', 'kaisai_tsukihi', 'keibajo_code', 'race_bango',
        'ketto_toroku_bango', 'umaban',
        'binary_probability', 'predicted_class'
    ]
    
    df_output = df[[col for col in output_cols if col in df.columns]]
    
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    try:
        df_output.to_csv(output_file, index=False, encoding='shift-jis')
    except:
        df_output.to_csv(output_file, index=False, encoding='utf-8')
    
    print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {output_file}")

def main():
    import sys
    
    if len(sys.argv) < 4:
        print("ä½¿ç”¨æ³•: python predict_phase3_inference.py [features_csv] [model_dir] [output_csv]")
        sys.exit(1)
    
    features_csv = sys.argv[1]
    model_dir = sys.argv[2]
    output_csv = sys.argv[3]
    
    print("="*80)
    print("Phase 3: äºŒå€¤åˆ†é¡äºˆæ¸¬")
    print("="*80)
    
    df = load_features_csv(features_csv)
    
    # ç«¶é¦¬å ´åã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’æ±ºå®š
    # ä¾‹: features/2026/02/èˆ¹æ©‹_20260214_features.csv â†’ models/binary/funabashi_2020-2025_v3_model.txt
    venue_name_jp = Path(features_csv).stem.split('_')[0]
    venue_name_en_map = {
        'é–€åˆ¥': 'monbetsu', 'ç››å²¡': 'morioka', 'æ°´æ²¢': 'mizusawa',
        'æµ¦å’Œ': 'urawa', 'èˆ¹æ©‹': 'funabashi', 'å¤§äº•': 'ooi', 'å·å´': 'kawasaki',
        'é‡‘æ²¢': 'kanazawa', 'ç¬ æ¾': 'kasamatsu', 'åå¤å±‹': 'nagoya',
        'åœ’ç”°': 'sonoda', 'å§«è·¯': 'himeji', 'é«˜çŸ¥': 'kochi', 'ä½è³€': 'saga'
    }
    venue_name_en = venue_name_en_map.get(venue_name_jp, 'unknown')
    
    model_path = f"{model_dir}/{venue_name_en}_2020-2025_v3_model.txt"
    
    model = load_lightgbm_model(model_path)
    
    # ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ï¼ˆ50å€‹ã€å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
    feature_columns = [col for col in df.columns if col not in [
        'kaisai_nen', 'kaisai_tsukihi', 'keibajo_code', 'race_bango',
        'ketto_toroku_bango', 'umaban', 'bamei', 'kakutei_chakujun'
    ]]
    
    df = predict_binary(df, model, feature_columns)
    
    save_binary_csv(df, output_csv)
    
    print("âœ… Phase 3 å®Œäº†")

if __name__ == "__main__":
    main()
```

---

## 5. Phase 5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆã®å®Ÿè£…ä¾‹

### 5.1 ä¸»è¦æ©Ÿèƒ½

**ãƒ•ã‚¡ã‚¤ãƒ«**: `scripts/phase5_ensemble/ensemble_predictions.py`

**æ©Ÿèƒ½æ¦‚è¦**:
- Phase 3, 4-1, 4-2 ã®äºˆæ¸¬çµæœã‚’çµ±åˆ
- é‡ã¿: Binary 30%, Ranking 50%, Regression 20%
- æœ€çµ‚ã‚¹ã‚³ã‚¢ã‚’0ã€œ1ã«æ­£è¦åŒ–

### 5.2 ã‚³ã‚¢å®Ÿè£…ï¼ˆç°¡ç•¥ç‰ˆï¼‰

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆï¼ˆåœ°æ–¹ç«¶é¦¬ç‰ˆï¼‰
"""

import pandas as pd
import numpy as np
from pathlib import Path

def normalize_score(series, ascending=True):
    """ã‚¹ã‚³ã‚¢ã‚’0ã€œ1ã«æ­£è¦åŒ–"""
    min_val = series.min()
    max_val = series.max()
    
    if max_val == min_val:
        return pd.Series([0.5] * len(series), index=series.index)
    
    if ascending:
        # å°ã•ã„ã»ã©è‰¯ã„ï¼ˆæ™‚é–“ãªã©ï¼‰
        normalized = 1.0 - (series - min_val) / (max_val - min_val)
    else:
        # å¤§ãã„ã»ã©è‰¯ã„ï¼ˆç¢ºç‡ãªã©ï¼‰
        normalized = (series - min_val) / (max_val - min_val)
    
    return normalized

def ensemble_predictions(binary_csv, ranking_csv, regression_csv, output_path,
                        weight_binary=0.3, weight_ranking=0.5, weight_regression=0.2):
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ"""
    
    print("="*80)
    print("Phase 5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ")
    print("="*80)
    
    # é‡ã¿ã®æ¤œè¨¼
    total_weight = weight_binary + weight_ranking + weight_regression
    if not np.isclose(total_weight, 1.0):
        weight_binary /= total_weight
        weight_ranking /= total_weight
        weight_regression /= total_weight
    
    print(f"\né‡ã¿è¨­å®š:")
    print(f"  - Binary: {weight_binary:.1%}")
    print(f"  - Ranking: {weight_ranking:.1%}")
    print(f"  - Regression: {weight_regression:.1%}")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    try:
        df_binary = pd.read_csv(binary_csv, encoding='shift-jis')
    except:
        df_binary = pd.read_csv(binary_csv, encoding='utf-8')
    
    try:
        df_ranking = pd.read_csv(ranking_csv, encoding='shift-jis')
    except:
        df_ranking = pd.read_csv(ranking_csv, encoding='utf-8')
    
    try:
        df_regression = pd.read_csv(regression_csv, encoding='shift-jis')
    except:
        df_regression = pd.read_csv(regression_csv, encoding='utf-8')
    
    print(f"âœ… Binary: {len(df_binary)}ä»¶")
    print(f"âœ… Ranking: {len(df_ranking)}ä»¶")
    print(f"âœ… Regression: {len(df_regression)}ä»¶")
    
    # ãƒ‡ãƒ¼ã‚¿çµåˆ
    df = df_binary.merge(
        df_ranking[['race_id', 'umaban', 'ranking_score', 'predicted_rank']],
        on=['race_id', 'umaban'],
        how='inner'
    )
    
    df = df.merge(
        df_regression[['race_id', 'umaban', 'predicted_time', 'time_rank']],
        on=['race_id', 'umaban'],
        how='inner'
    )
    
    print(f"âœ… çµåˆå¾Œ: {len(df)}ä»¶")
    
    # ã‚¹ã‚³ã‚¢æ­£è¦åŒ–ï¼ˆãƒ¬ãƒ¼ã‚¹ã”ã¨ï¼‰
    df['binary_normalized'] = df.groupby('race_id')['binary_probability'].transform(
        lambda x: normalize_score(x, ascending=False)
    )
    
    df['ranking_normalized'] = df.groupby('race_id')['ranking_score'].transform(
        lambda x: normalize_score(x, ascending=False)
    )
    
    df['regression_normalized'] = df.groupby('race_id')['predicted_time'].transform(
        lambda x: normalize_score(x, ascending=True)
    )
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚¹ã‚³ã‚¢è¨ˆç®—
    df['ensemble_score'] = (
        df['binary_normalized'] * weight_binary +
        df['ranking_normalized'] * weight_ranking +
        df['regression_normalized'] * weight_regression
    )
    
    print(f"âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚¹ã‚³ã‚¢è¨ˆç®—å®Œäº†")
    print(f"  - å¹³å‡: {df['ensemble_score'].mean():.4f}")
    print(f"  - æœ€å¤§: {df['ensemble_score'].max():.4f}")
    print(f"  - æœ€å°: {df['ensemble_score'].min():.4f}")
    
    # æœ€çµ‚é †ä½æ±ºå®š
    df['final_rank'] = df.groupby('race_id')['ensemble_score'].rank(
        ascending=False, method='min'
    ).astype(int)
    
    # ä¿å­˜
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    output_cols = [
        'race_id', 'kaisai_nen', 'kaisai_tsukihi', 'keibajo_code', 'race_bango',
        'ketto_toroku_bango', 'umaban',
        'ensemble_score', 'final_rank',
        'binary_probability', 'predicted_class',
        'ranking_score', 'predicted_rank',
        'predicted_time', 'time_rank'
    ]
    
    df_output = df[[col for col in output_cols if col in df.columns]]
    
    try:
        df_output.to_csv(output_file, index=False, encoding='shift-jis')
    except:
        df_output.to_csv(output_file, index=False, encoding='utf-8')
    
    print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {output_file}")
    print("="*80)
    print("âœ… Phase 5 ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆå®Œäº†")
    print("="*80)
    
    return df_output

def main():
    import sys
    
    if len(sys.argv) < 5:
        print("ä½¿ç”¨æ³•: python ensemble_predictions.py [binary_csv] [ranking_csv] [regression_csv] [output_csv]")
        sys.exit(1)
    
    binary_csv = sys.argv[1]
    ranking_csv = sys.argv[2]
    regression_csv = sys.argv[3]
    output_csv = sys.argv[4]
    
    ensemble_predictions(binary_csv, ranking_csv, regression_csv, output_csv)

if __name__ == "__main__":
    main()
```

---

## 6. Phase 6: è²·ã„ç›®ç”Ÿæˆã®å®Ÿè£…ä¾‹

### 6.1 ä¸»è¦æ©Ÿèƒ½

**ãƒ•ã‚¡ã‚¤ãƒ«**: `scripts/phase6_betting/generate_distribution_note.py`

**æ©Ÿèƒ½æ¦‚è¦**:
- ensemble CSV ã‹ã‚‰ NoteæŠ•ç¨¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
- å„ãƒ¬ãƒ¼ã‚¹ã®TOPé¦¬ã¨è²·ã„ç›®ã‚’è¡¨ç¤º
- ä¸‰é€£è¤‡ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: `1ãƒ»2ä½ - 2ãƒ»3ãƒ»4ä½ - 2ãƒ»3ãƒ»4ãƒ»5ãƒ»6ãƒ»7ä½`

### 6.2 ã‚³ã‚¢å®Ÿè£…ï¼ˆç°¡ç•¥ç‰ˆï¼‰

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 6: è²·ã„ç›®ç”Ÿæˆ - NoteæŠ•ç¨¿ç”¨ï¼ˆåœ°æ–¹ç«¶é¦¬ç‰ˆï¼‰
"""

import pandas as pd
from pathlib import Path

def load_ensemble_csv(ensemble_csv_path):
    """ensemble CSVã‚’èª­ã¿è¾¼ã¿"""
    try:
        df = pd.read_csv(ensemble_csv_path, encoding='shift-jis')
    except:
        df = pd.read_csv(ensemble_csv_path, encoding='utf-8')
    
    print(f"âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}ä»¶")
    return df

def assign_rank_label(score):
    """ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦ãƒ©ãƒ³ã‚¯ãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸"""
    if score >= 0.80:
        return 'S'
    elif score >= 0.70:
        return 'A'
    elif score >= 0.60:
        return 'B'
    elif score >= 0.50:
        return 'C'
    else:
        return 'D'

def generate_betting_recommendations(df_race):
    """è²·ã„ç›®æ¨å¥¨ã‚’ç”Ÿæˆ"""
    top_horses = df_race.nsmallest(7, 'final_rank')['umaban'].tolist()
    
    if len(top_horses) < 3:
        return ""
    
    h1 = top_horses[0]
    h2 = top_horses[1] if len(top_horses) > 1 else None
    h3 = top_horses[2] if len(top_horses) > 2 else None
    
    # å˜å‹ãƒ»è¤‡å‹
    recommendations = []
    recommendations.append(f"- å˜å‹: **{h1}ç•ª**")
    recommendations.append(f"- è¤‡å‹: **{h1}ç•ª**ã€{h2}ç•ª")
    
    # é¦¬å˜
    umatan = []
    if h2:
        umatan.append(f"{h1}â†’{h2}")
        umatan.append(f"{h2}â†’{h1}")
    if h3:
        umatan.append(f"{h1}â†’{h3}")
        umatan.append(f"{h3}â†’{h1}")
    recommendations.append(f"- é¦¬å˜: {', '.join(umatan)}")
    
    # ä¸‰é€£è¤‡ï¼ˆæ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: 1ãƒ»2ä½ - 2ãƒ»3ãƒ»4ä½ - 2ãƒ»3ãƒ»4ãƒ»5ãƒ»6ãƒ»7ä½ï¼‰
    if len(top_horses) >= 7:
        first_positions = [h1, h2]
        second_place = top_horses[1:4]  # 2, 3, 4ä½
        third_place = top_horses[1:7]   # 2, 3, 4, 5, 6, 7ä½
        
        sanrenpuku_text = f"{'.'.join(map(str, first_positions))} - {'.'.join(map(str, second_place))} - {'.'.join(map(str, third_place))}"
        recommendations.append(f"- ä¸‰é€£è¤‡: {sanrenpuku_text}")
    
    return "\n".join(recommendations)

def generate_note_text(df, venue_name, target_date):
    """NoteæŠ•ç¨¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    output = []
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    output.append("# ğŸ‡ åœ°æ–¹ç«¶é¦¬ AIäºˆæƒ³")
    output.append(f"\n**é–‹å‚¬æ—¥**: {target_date}")
    output.append(f"**ç«¶é¦¬å ´**: {venue_name}")
    output.append(f"**å¯¾è±¡ãƒ¬ãƒ¼ã‚¹**: {df['race_bango'].nunique()}R")
    output.append("\n---\n")
    
    # å„ãƒ¬ãƒ¼ã‚¹ã®äºˆæƒ³
    for race_num in sorted(df['race_bango'].unique()):
        df_race = df[df['race_bango'] == race_num].copy()
        df_race = df_race.sort_values('final_rank')
        
        output.append(f"## ğŸ‡ ç¬¬{race_num}R äºˆæƒ³\n")
        output.append("### ğŸ“Š äºˆæƒ³é †ä½\n")
        
        # TOP3è¡¨ç¤º
        for idx, row in df_race.head(3).iterrows():
            umaban = int(row['umaban'])
            bamei = row.get('bamei', 'æœªç™»éŒ²')
            score = row['ensemble_score']
            rank_label = assign_rank_label(score)
            
            if idx == df_race.index[0]:
                output.append(f"**1. {umaban}ç•ª {bamei}** ï¼ˆã‚¹ã‚³ã‚¢: {score:.2f} / {rank_label}ï¼‰")
            else:
                output.append(f"{row['final_rank']}. {umaban}ç•ª {bamei} ï¼ˆã‚¹ã‚³ã‚¢: {score:.2f} / {rank_label}ï¼‰")
        
        output.append("\n### ğŸ’° è³¼å…¥æ¨å¥¨\n")
        betting_text = generate_betting_recommendations(df_race)
        output.append(betting_text)
        output.append("\n---\n")
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    output.append("\nâš ï¸ **ã”åˆ©ç”¨ä¸Šã®æ³¨æ„**")
    output.append("æœ¬äºˆæƒ³ã¯AIã«ã‚ˆã‚‹çµ±è¨ˆåˆ†æã«åŸºã¥ããƒ‡ãƒ¼ã‚¿ã§ã™ã€‚")
    output.append("ãƒ¬ãƒ¼ã‚¹çµæœã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    output.append("é¦¬åˆ¸è³¼å…¥ã¯è‡ªå·±åˆ¤æ–­ãƒ»è‡ªå·±è²¬ä»»ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚")
    
    return "\n".join(output)

def save_note_text(text, output_path):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(text)
    
    print(f"ğŸ’¾ NoteæŠ•ç¨¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜: {output_file}")

def main():
    import sys
    
    if len(sys.argv) < 3:
        print("ä½¿ç”¨æ³•: python generate_distribution_note.py [ensemble_csv] [output_txt]")
        sys.exit(1)
    
    ensemble_csv = sys.argv[1]
    output_txt = sys.argv[2]
    
    print("="*80)
    print("Phase 6: NoteæŠ•ç¨¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ")
    print("="*80)
    
    df = load_ensemble_csv(ensemble_csv)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ç«¶é¦¬å ´åã¨æ—¥ä»˜ã‚’æŠ½å‡º
    filename = Path(ensemble_csv).stem
    parts = filename.split('_')
    venue_name = parts[0]
    date_str = parts[1] if len(parts) > 1 else "ä¸æ˜"
    
    text = generate_note_text(df, venue_name, date_str)
    
    save_note_text(text, output_txt)
    
    print("âœ… Phase 6 å®Œäº†")

if __name__ == "__main__":
    main()
```

---

## 7. JRAç‰ˆã§ã®å¤‰æ›´ãƒã‚¤ãƒ³ãƒˆ

### 7.1 Phase 0: ãƒ‡ãƒ¼ã‚¿å–å¾—

**å¤‰æ›´å†…å®¹**:
- ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: PC-KEIBA PostgreSQL â†’ **JRA-VAN Data Lab + JRDB**
- ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰: åœ°æ–¹14å ´ â†’ **JRA10å ´**
- ã‚«ãƒ©ãƒ è¿½åŠ : **track_typeï¼ˆèŠ/ãƒ€ãƒ¼ãƒˆ/éšœå®³ï¼‰**, **track_conditionï¼ˆè‰¯/ç¨é‡/é‡/ä¸è‰¯ï¼‰**

### 7.2 Phase 1: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

**è¿½åŠ ç‰¹å¾´é‡**:
```python
# èŠãƒ»ãƒ€ãƒ¼ãƒˆåŒºåˆ¥
'track_type_turf',  # èŠ (One-Hot)
'track_type_dirt',  # ãƒ€ãƒ¼ãƒˆ (One-Hot)
'track_type_jump',  # éšœå®³ (One-Hot)

# èŠãƒ»ãƒ€ãƒ¼ãƒˆåˆ¥å‹ç‡
'turf_win_rate',
'dirt_win_rate',

# ã‚³ãƒ¼ã‚¹å½¢çŠ¶
'track_direction',     # å³å›ã‚Š/å·¦å›ã‚Š
'straight_length',     # ç›´ç·šè·é›¢ï¼ˆmï¼‰
'course_category',     # å¹³å¦/å‚/æ€¥å‚

# é–‹å‚¬æ™‚æœŸ
'season_spring',   # æ˜¥ (One-Hot)
'season_summer',   # å¤ (One-Hot)
'season_autumn',   # ç§‹ (One-Hot)
'season_winter',   # å†¬ (One-Hot)

# ã‚°ãƒ¬ãƒ¼ãƒ‰
'grade_g1',  # G1 (One-Hot)
'grade_g2',  # G2 (One-Hot)
'grade_g3',  # G3 (One-Hot)

# è³é‡‘ãƒ»å‡ºèµ°é ­æ•°
'prize_money',  # è³é‡‘é¡
'field_size',   # å‡ºèµ°é ­æ•°
```

### 7.3 Phase 6: è²·ã„ç›®ç”Ÿæˆ

**WIN5å¯¾å¿œ**:
```python
def generate_win5_tickets(df, target_races):
    """WIN5è²·ã„ç›®ç”Ÿæˆï¼ˆæŒ‡å®š5ãƒ¬ãƒ¼ã‚¹ã®TOP3çµ„ã¿åˆã‚ã›ï¼‰"""
    tickets = []
    
    for race_num in target_races:
        df_race = df[df['race_bango'] == race_num]
        top3 = df_race.nsmallest(3, 'final_rank')['umaban'].tolist()
        tickets.append(top3)
    
    # 3^5 = 243é€šã‚Šã®çµ„ã¿åˆã‚ã›ç”Ÿæˆ
    from itertools import product
    combinations = list(product(*tickets))
    
    print(f"WIN5 è³¼å…¥ç‚¹æ•°: {len(combinations)}ç‚¹")
    print(f"æŠ•è³‡é¡: {len(combinations) * 100}å††")
    
    return combinations
```

---

## 8. JRA-VAN + JRDB äºŒæœ¬ç«‹ã¦ãƒ‡ãƒ¼ã‚¿å–å¾—æˆ¦ç•¥

### 8.1 ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ¯”è¼ƒ

| é …ç›® | JRA-VAN Data Lab | JRDB |
|------|------------------|------|
| å…¬å¼æ€§ | âœ… JRAå…¬å¼ | â­• éå…¬å¼ï¼ˆé«˜ç²¾åº¦ï¼‰ |
| ãƒ‡ãƒ¼ã‚¿é‡ | âœ… å®Œå…¨ç¶²ç¾… | âœ… å®Œå…¨ç¶²ç¾… |
| æ›´æ–°é »åº¦ | âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  | âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  |
| ç‰¹å¾´é‡ | â­• åŸºæœ¬æƒ…å ±ã®ã¿ | âœ… **ç‹¬è‡ªæŒ‡æ•°è±Šå¯Œ** |
| ã‚³ã‚¹ãƒˆ | æœˆé¡æ•°åƒå†† | æœˆé¡æ•°åƒå†† |
| API | âœ… JV-Link SDK | âœ… JRDB SDK |
| åˆ©ç‚¹ | å…¬å¼ä¿¡é ¼æ€§ | **äºˆæƒ³ç²¾åº¦å‘ä¸Š** |

### 8.2 æ¨å¥¨æˆ¦ç•¥: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

#### ãªãœäºŒæœ¬ç«‹ã¦ãŒæœ€é©ã‹ï¼Ÿ

**JRA-VANã®å¼·ã¿**: å…¬å¼ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®ä¿¡é ¼æ€§ã€ã‚ªãƒƒã‚ºãƒ»çµæœã®æ­£ç¢ºæ€§  
**JRDBã®å¼·ã¿**: 40å¹´ä»¥ä¸Šã®å®Ÿç¸¾ã‚’æŒã¤ç‹¬è‡ªæŒ‡æ•°ï¼ˆã‚¿ã‚¤ãƒ æŒ‡æ•°ã€ãƒšãƒ¼ã‚¹æŒ‡æ•°ã€é¦¬å ´æŒ‡æ•°ãªã©ï¼‰ã«ã‚ˆã‚‹äºˆæƒ³ç²¾åº¦å‘ä¸Š

#### ãƒ‡ãƒ¼ã‚¿åˆ†æ‹…

```
[JRA-VAN Data Lab]
- åŸºæœ¬ãƒ¬ãƒ¼ã‚¹æƒ…å ±ï¼ˆé¦¬åã€é¨æ‰‹ã€èª¿æ•™å¸«ã€æ ç•ªã€æ–¤é‡ï¼‰
- éå»æˆç¸¾ï¼ˆç€é †ã€èµ°ç ´ã‚¿ã‚¤ãƒ ï¼‰
- é¦¬å ´çŠ¶æ…‹ã€å¤©å€™
- **ã‚ªãƒƒã‚ºæƒ…å ±ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰**
- æ‰•æˆ»é‡‘æƒ…å ±ï¼ˆå®Ÿç¸¾ï¼‰

[JRDB]
- **ç‹¬è‡ªæŒ‡æ•°ï¼ˆèµ°ç ´ã‚¿ã‚¤ãƒ æŒ‡æ•°ã€ãƒšãƒ¼ã‚¹æŒ‡æ•°ã€é¦¬å ´æŒ‡æ•°ï¼‰**
- **IDMï¼ˆç·åˆæŒ‡æ•°ï¼‰** - JRDBã®æ ¸å¿ƒçš„ãªè©•ä¾¡æŒ‡æ¨™
- **é¨æ‰‹æŒ‡æ•°ãƒ»èª¿æ•™å¸«æŒ‡æ•°** - äººæ°—ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šç²¾åº¦é«˜ã„
- è¡€çµ±è©•ä¾¡ãƒ»è¡€çµ±ãƒã‚¤ãƒ³ãƒˆ
- ã‚³ãƒ¼ã‚¹é©æ€§ãƒ»è·é›¢é©æ€§
- å±•é–‹äºˆæƒ³ï¼ˆé€ƒã’/å…ˆè¡Œ/å·®ã—/è¿½è¾¼ï¼‰
- èª¿æ•™è©•ä¾¡ï¼ˆè¿½ã„åˆ‡ã‚Šã‚¿ã‚¤ãƒ ï¼‰
- å©èˆã‚³ãƒ¡ãƒ³ãƒˆ
```

#### ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè£…ã®æµã‚Œ

```
Step 1: JRA-VANã‹ã‚‰åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—
  â†“ é¦¬åã€é¨æ‰‹ã€æ ç•ªã€éå»æˆç¸¾ã€ã‚ªãƒƒã‚º
  
Step 2: JRDBã‹ã‚‰ç‹¬è‡ªæŒ‡æ•°å–å¾—
  â†“ IDMã€ã‚¿ã‚¤ãƒ æŒ‡æ•°ã€ãƒšãƒ¼ã‚¹æŒ‡æ•°ã€è¡€çµ±è©•ä¾¡
  
Step 3: ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ï¼ˆrace_id + umaban ã§JOINï¼‰
  â†“ çµ±åˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
  
Step 4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
  â†“ JRA-VANåŸºæœ¬ç‰¹å¾´é‡ + JRDBç‹¬è‡ªæŒ‡æ•°
  
Step 5: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»äºˆæ¸¬
  â†“ ç²¾åº¦å‘ä¸Šï¼ˆAUC 0.77 â†’ **0.85ä»¥ä¸Š**ã‚’ç›®æ¨™ï¼‰
```

#### å®Ÿè£…ä¾‹

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 0: JRA ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆJRA-VAN + JRDB ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰
"""

import pandas as pd
from jvlink import JVLink  # JRA-VAN SDK
import jrdb_api  # JRDB SDKï¼ˆä»®æƒ³çš„ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åï¼‰

def fetch_from_jravan(race_date, venue_codes):
    """JRA-VANã‹ã‚‰åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    jv = JVLink()
    jv.init()
    
    # ãƒ¬ãƒ¼ã‚¹æƒ…å ±å–å¾—
    races = jv.get_race_info(
        date=race_date,
        venues=venue_codes
    )
    
    # å‡ºé¦¬è¡¨å–å¾—
    horses = jv.get_horse_info(
        date=race_date,
        venues=venue_codes
    )
    
    # ã‚ªãƒƒã‚ºæƒ…å ±å–å¾—ï¼ˆãƒ¬ãƒ¼ã‚¹ç›´å‰ï¼‰
    odds = jv.get_odds(
        date=race_date,
        venues=venue_codes
    )
    
    # DataFrameã«å¤‰æ›
    df_jravan = pd.DataFrame({
        'race_id': races['race_id'],
        'umaban': horses['umaban'],
        'bamei': horses['bamei'],
        'jockey_name': horses['jockey_name'],
        'kinryo': horses['kinryo'],
        'wakuban': horses['wakuban'],
        'prev1_rank': horses['prev1_rank'],
        'prev2_rank': horses['prev2_rank'],
        'prev3_rank': horses['prev3_rank'],
        'odds_win': odds['win_odds']
    })
    
    print(f"âœ… JRA-VAN ãƒ‡ãƒ¼ã‚¿å–å¾—: {len(df_jravan)}ä»¶")
    return df_jravan

def fetch_from_jrdb(race_date, venue_codes):
    """JRDBã‹ã‚‰ç‹¬è‡ªæŒ‡æ•°ã‚’å–å¾—"""
    # JRDB APIæ¥ç¶š
    api = jrdb_api.JRDB_API(api_key="YOUR_JRDB_API_KEY")
    
    # ç‹¬è‡ªæŒ‡æ•°å–å¾—
    indices = api.get_race_indices(
        date=race_date,
        venues=venue_codes
    )
    
    df_jrdb = pd.DataFrame({
        'race_id': indices['race_id'],
        'umaban': indices['umaban'],
        'idm': indices['idm'],  # IDMï¼ˆç·åˆæŒ‡æ•°ï¼‰
        'time_index': indices['time_index'],  # ã‚¿ã‚¤ãƒ æŒ‡æ•°
        'pace_index': indices['pace_index'],  # ãƒšãƒ¼ã‚¹æŒ‡æ•°
        'track_index': indices['track_index'],  # é¦¬å ´æŒ‡æ•°
        'jockey_index': indices['jockey_index'],  # é¨æ‰‹æŒ‡æ•°
        'trainer_index': indices['trainer_index'],  # èª¿æ•™å¸«æŒ‡æ•°
        'pedigree_point': indices['pedigree_point'],  # è¡€çµ±ãƒã‚¤ãƒ³ãƒˆ
        'course_aptitude': indices['course_aptitude'],  # ã‚³ãƒ¼ã‚¹é©æ€§
        'running_style': indices['running_style']  # è„šè³ªï¼ˆé€ƒã’/å…ˆè¡Œ/å·®ã—/è¿½è¾¼ï¼‰
    })
    
    print(f"âœ… JRDB ãƒ‡ãƒ¼ã‚¿å–å¾—: {len(df_jrdb)}ä»¶")
    return df_jrdb

def merge_jravan_jrdb(df_jravan, df_jrdb):
    """JRA-VANã¨JRDBã‚’ãƒãƒ¼ã‚¸"""
    # race_id, umaban ã§ãƒãƒ¼ã‚¸
    df_merged = df_jravan.merge(
        df_jrdb,
        on=['race_id', 'umaban'],
        how='left',  # JRA-VANã‚’åŸºæº–ã«LEFT JOIN
        suffixes=('_jravan', '_jrdb')
    )
    
    # JRDBæŒ‡æ•°ãŒæ¬ æã—ã¦ã„ã‚‹å ´åˆã¯0åŸ‹ã‚
    jrdb_cols = ['idm', 'time_index', 'pace_index', 'track_index', 
                 'jockey_index', 'trainer_index', 'pedigree_point', 
                 'course_aptitude']
    for col in jrdb_cols:
        if col in df_merged.columns:
            df_merged[col] = df_merged[col].fillna(0)
    
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸å®Œäº†: {len(df_merged)}ä»¶")
    print(f"  - JRA-VANåŸºæœ¬æƒ…å ±: {df_jravan.shape[1]}ã‚«ãƒ©ãƒ ")
    print(f"  - JRDBç‹¬è‡ªæŒ‡æ•°: {df_jrdb.shape[1]}ã‚«ãƒ©ãƒ ")
    print(f"  - çµ±åˆãƒ‡ãƒ¼ã‚¿: {df_merged.shape[1]}ã‚«ãƒ©ãƒ ")
    
    return df_merged

def save_to_csv(df, race_date, output_dir="data/raw"):
    """CSVå½¢å¼ã§ä¿å­˜"""
    year = race_date[:4]
    month = race_date[5:7]
    date_short = race_date.replace("-", "")
    
    from pathlib import Path
    output_path = Path(output_dir) / year / month
    output_path.mkdir(parents=True, exist_ok=True)
    
    output_file = output_path / f"JRA_{date_short}_raw.csv"
    df.to_csv(output_file, index=False, encoding='shift-jis')
    
    print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {output_file}")
    return str(output_file)

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Phase 0: JRA ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆJRA-VAN + JRDBï¼‰')
    parser.add_argument('--date', type=str, required=True, help='æ—¥ä»˜ï¼ˆä¾‹: 2026-02-14ï¼‰')
    args = parser.parse_args()
    
    race_date = args.date
    venue_codes = ['05', '06', '08', '09', '10', '11', '12', '13', '14', '15']  # JRA10å ´
    
    print("="*80)
    print("Phase 0: JRA ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆJRA-VAN + JRDB ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰")
    print("="*80)
    print(f"å¯¾è±¡æ—¥ä»˜: {race_date}")
    print(f"å¯¾è±¡ç«¶é¦¬å ´: æœ­å¹Œã€å‡½é¤¨ã€ç¦å³¶ã€æ–°æ½Ÿã€æ±äº¬ã€ä¸­å±±ã€ä¸­äº¬ã€äº¬éƒ½ã€é˜ªç¥ã€å°å€‰")
    
    # JRA-VANã‹ã‚‰åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—
    df_jravan = fetch_from_jravan(race_date, venue_codes)
    
    # JRDBã‹ã‚‰ç‹¬è‡ªæŒ‡æ•°å–å¾—
    df_jrdb = fetch_from_jrdb(race_date, venue_codes)
    
    # ãƒãƒ¼ã‚¸
    df_merged = merge_jravan_jrdb(df_jravan, df_jrdb)
    
    # CSVä¿å­˜
    output_file = save_to_csv(df_merged, race_date)
    
    print("="*80)
    print("âœ… Phase 0 å®Œäº†")
    print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
    print("="*80)

if __name__ == "__main__":
    main()
```

### 8.3 JRDBç‹¬è‡ªæŒ‡æ•°ã®æ´»ç”¨

#### JRDBæŒ‡æ•°ä¸€è¦§

```python
# JRDBç‹¬è‡ªæŒ‡æ•°ã®ä¾‹ï¼ˆPhase 1ã®ç‰¹å¾´é‡ã«è¿½åŠ ï¼‰
JRDB_INDICES = [
    # ã€æœ€é‡è¦ã€‘ç·åˆè©•ä¾¡
    'idm',                    # IDMï¼ˆç·åˆæŒ‡æ•°ï¼‰ - JRDBã®æ ¸å¿ƒæŒ‡æ¨™
    
    # ã‚¿ã‚¤ãƒ ãƒ»ã‚¹ãƒ”ãƒ¼ãƒ‰ç³»
    'time_index',             # èµ°ç ´ã‚¿ã‚¤ãƒ æŒ‡æ•°
    'pace_index',             # ãƒšãƒ¼ã‚¹æŒ‡æ•°
    'speed_ability',          # ã‚¹ãƒ”ãƒ¼ãƒ‰èƒ½åŠ›
    
    # é¦¬å ´ãƒ»ã‚³ãƒ¼ã‚¹é©æ€§
    'track_index',            # é¦¬å ´æŒ‡æ•°
    'course_aptitude',        # ã‚³ãƒ¼ã‚¹é©æ€§
    'distance_aptitude',      # è·é›¢é©æ€§
    'track_condition_aptitude',  # é¦¬å ´çŠ¶æ…‹é©æ€§ï¼ˆè‰¯/ç¨é‡/é‡/ä¸è‰¯ï¼‰
    
    # äººçš„è¦ç´ 
    'jockey_index',           # é¨æ‰‹æŒ‡æ•°
    'trainer_index',          # èª¿æ•™å¸«æŒ‡æ•°
    'stable_index',           # å©èˆæŒ‡æ•°
    
    # è¡€çµ±ãƒ»å±•é–‹
    'pedigree_index',         # è¡€çµ±æŒ‡æ•°
    'pedigree_point',         # è¡€çµ±ãƒã‚¤ãƒ³ãƒˆ
    'running_style',          # è„šè³ªï¼ˆé€ƒã’/å…ˆè¡Œ/å·®ã—/è¿½è¾¼ï¼‰
    'running_style_score',    # è„šè³ªã‚¹ã‚³ã‚¢
    
    # èª¿æ•™ãƒ»é¦¬ä½“
    'training_evaluation',    # èª¿æ•™è©•ä¾¡
    'horse_condition',        # é¦¬ä½“è©•ä¾¡
    'weight_change_evaluation',  # é¦¬ä½“é‡å¢—æ¸›è©•ä¾¡
    
    # å±•é–‹äºˆæƒ³
    'position_prediction',    # ä½ç½®å–ã‚Šäºˆæƒ³
    'pace_prediction',        # ãƒšãƒ¼ã‚¹äºˆæƒ³
]
```

#### Phase 1ã§ã®æ´»ç”¨æ–¹æ³•

```python
def create_jrdb_features(df):
    """JRDBæŒ‡æ•°ã‚’ç‰¹å¾´é‡ã«è¿½åŠ """
    
    # 1. IDMï¼ˆç·åˆæŒ‡æ•°ï¼‰ã‚’æ­£è¦åŒ–ï¼ˆ0ã€œ1ï¼‰
    df['idm_normalized'] = (df['idm'] - df['idm'].min()) / (df['idm'].max() - df['idm'].min())
    
    # 2. ã‚¿ã‚¤ãƒ æŒ‡æ•°ã¨ãƒšãƒ¼ã‚¹æŒ‡æ•°ã®çµ„ã¿åˆã‚ã›
    df['time_pace_combo'] = df['time_index'] * 0.6 + df['pace_index'] * 0.4
    
    # 3. é¨æ‰‹æŒ‡æ•°ã¨èª¿æ•™å¸«æŒ‡æ•°ã®çµ„ã¿åˆã‚ã›
    df['rider_trainer_combo'] = df['jockey_index'] * 0.7 + df['trainer_index'] * 0.3
    
    # 4. ã‚³ãƒ¼ã‚¹é©æ€§ã¨è·é›¢é©æ€§ã®æ›ã‘åˆã‚ã›
    df['course_distance_fit'] = df['course_aptitude'] * df['distance_aptitude']
    
    # 5. è„šè³ªã‚¹ã‚³ã‚¢ã®æ•°å€¤åŒ–ï¼ˆé€ƒã’=4, å…ˆè¡Œ=3, å·®ã—=2, è¿½è¾¼=1ï¼‰
    style_map = {'é€ƒã’': 4, 'å…ˆè¡Œ': 3, 'å·®ã—': 2, 'è¿½è¾¼': 1}
    df['running_style_num'] = df['running_style'].map(style_map).fillna(0)
    
    # 6. è¡€çµ±ãƒã‚¤ãƒ³ãƒˆã®éšç´šåŒ–
    df['pedigree_class_high'] = (df['pedigree_point'] >= 80).astype(int)
    df['pedigree_class_mid'] = ((df['pedigree_point'] >= 60) & (df['pedigree_point'] < 80)).astype(int)
    df['pedigree_class_low'] = (df['pedigree_point'] < 60).astype(int)
    
    return df
```

#### JRA-VAN vs JRDB vs ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã®ç²¾åº¦æ¯”è¼ƒï¼ˆäºˆæƒ³ï¼‰

| ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ | Phase 3 AUC | Phase 4 ç€é †çš„ä¸­ç‡ | Phase 9 å›åç‡ | æ¨å¥¨åº¦ |
|-------------|-------------|-------------------|---------------|-------|
| JRA-VANã®ã¿ | 0.73 | 28% | 85% | â­• |
| JRDBã®ã¿ | 0.79 | 35% | 105% | âœ… |
| **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰** | **0.85ä»¥ä¸Š** | **40%ä»¥ä¸Š** | **120%ä»¥ä¸Š** | ğŸ† **æœ€æ¨å¥¨** |

#### ã‚³ã‚¹ãƒˆè©¦ç®—

```
JRA-VAN Data Lab: æœˆé¡ 3,000å††ã€œ5,000å††
JRDB: æœˆé¡ 3,000å††ã€œ5,000å††
åˆè¨ˆ: æœˆé¡ 6,000å††ã€œ10,000å††

å›åç‡120%ã‚’ç›®æ¨™ã¨ã—ãŸå ´åˆ:
- æœˆé–“æŠ•è³‡é¡: 10ä¸‡å††
- æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³: 12ä¸‡å††
- åˆ©ç›Š: 2ä¸‡å††
- ãƒ‡ãƒ¼ã‚¿è²»ç”¨: 1ä¸‡å††
â†’ å®Ÿè³ªåˆ©ç›Š: 1ä¸‡å††/æœˆï¼ˆå›åç‡110%ç›¸å½“ï¼‰

â€»ãŸã ã—äºˆæƒ³ã¯ä¸ç¢ºå®Ÿæ€§ã‚’ä¼´ã†ãŸã‚ã€è³‡é‡‘ç®¡ç†ï¼ˆKellyåŸºæº–ï¼‰ãŒå¿…é ˆ
```

---

## 9. æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ç”¨ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

### 9.1 å®Œå…¨ãªæŒ‡ç¤ºæ–‡

```markdown
# ğŸ‡ ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰AIäºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã®ä¾é ¼

ã“ã‚“ã«ã¡ã¯ï¼æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰ç‰ˆAIäºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

## ğŸ“‹ å‰ææƒ…å ±

### æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ 
- **åœ°æ–¹ç«¶é¦¬AIäºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ** ãŒå®Œæˆã—ã¦ã„ã¾ã™ï¼ˆPhase 0-11ã€100%å®Œæˆï¼‰
- GitHubãƒªãƒã‚¸ãƒˆãƒª: https://github.com/aka209859-max/anonymous-keiba-ai
- ãƒ–ãƒ©ãƒ³ãƒ: `phase0_complete_fix_2026_02_07`
- æœ€æ–°ã‚³ãƒŸãƒƒãƒˆ: `aa4bb50`

### å®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
ä»¥ä¸‹ã®MDãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜ã—ã¦ã„ã¾ã™:
1. **JRA_VERSION_COMPLETE_REFERENCE.md** - æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ï¼ˆã‚³ãƒ¼ãƒ‰ä¾‹è¾¼ã¿ï¼‰
2. **JRA_VERSION_INSTRUCTIONS.md** - å®Ÿè£…æ‰‹é †è©³ç´°

ã“ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™:
- Phase 0ã€œ11ã®å®Œå…¨ãªã‚³ãƒ¼ãƒ‰å®Ÿè£…ä¾‹ï¼ˆã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆå¯èƒ½ï¼‰
- ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è§£èª¬
- åœ°æ–¹ç«¶é¦¬ã¨JRAã®é•ã„ã®è©³ç´°
- JRAç‰ˆã§ã®å¤‰æ›´ãƒã‚¤ãƒ³ãƒˆ
- **JRA-VAN + JRDB äºŒæœ¬ç«‹ã¦ãƒ‡ãƒ¼ã‚¿å–å¾—æˆ¦ç•¥**

## ğŸ¯ æ–°è¦é–‹ç™ºç›®æ¨™

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå**: jra-keiba-ai
- **å¯¾è±¡**: ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰10ç«¶é¦¬å ´
  - æœ­å¹Œã€å‡½é¤¨ã€ç¦å³¶ã€æ–°æ½Ÿã€æ±äº¬ã€ä¸­å±±ã€ä¸­äº¬ã€äº¬éƒ½ã€é˜ªç¥ã€å°å€‰
- **ãƒ™ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ **: åœ°æ–¹ç«¶é¦¬ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æµç”¨
- **ç‹¬ç«‹æ€§**: å®Œå…¨ã«ç‹¬ç«‹ã—ãŸæ–°è¦GitHubãƒªãƒã‚¸ãƒˆãƒª

### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æˆ¦ç•¥ï¼ˆé‡è¦ï¼‰
**JRA-VAN Data Lab + JRDB ã®äºŒæœ¬ç«‹ã¦ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**ã‚’æ¡ç”¨ã—ã¾ã™ã€‚

#### ãªãœäºŒæœ¬ç«‹ã¦ãŒæœ€é©ã‹ï¼Ÿ
- **JRA-VAN**: å…¬å¼ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®ä¿¡é ¼æ€§ã€ã‚ªãƒƒã‚ºãƒ»çµæœã®æ­£ç¢ºæ€§
- **JRDB**: 40å¹´ä»¥ä¸Šã®å®Ÿç¸¾ã‚’æŒã¤ç‹¬è‡ªæŒ‡æ•°ï¼ˆIDMã€ã‚¿ã‚¤ãƒ æŒ‡æ•°ã€ãƒšãƒ¼ã‚¹æŒ‡æ•°ãªã©ï¼‰ã«ã‚ˆã‚‹äºˆæƒ³ç²¾åº¦å‘ä¸Š
- **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åŠ¹æœ**: AUC 0.77 â†’ **0.85ä»¥ä¸Š**ã€å›åç‡ 60% â†’ **120%ä»¥ä¸Š**ã‚’ç›®æ¨™

#### ãƒ‡ãƒ¼ã‚¿åˆ†æ‹…
```
[JRA-VAN Data Lab]
- åŸºæœ¬æƒ…å ±ï¼ˆé¦¬åã€é¨æ‰‹ã€èª¿æ•™å¸«ã€æ ç•ªã€æ–¤é‡ï¼‰
- éå»æˆç¸¾ï¼ˆç€é †ã€èµ°ç ´ã‚¿ã‚¤ãƒ ï¼‰
- é¦¬å ´çŠ¶æ…‹ã€å¤©å€™
- ã‚ªãƒƒã‚ºæƒ…å ±ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰

[JRDB]
- IDMï¼ˆç·åˆæŒ‡æ•°ï¼‰ - JRDBã®æ ¸å¿ƒçš„ãªè©•ä¾¡æŒ‡æ¨™
- ç‹¬è‡ªæŒ‡æ•°ï¼ˆã‚¿ã‚¤ãƒ æŒ‡æ•°ã€ãƒšãƒ¼ã‚¹æŒ‡æ•°ã€é¦¬å ´æŒ‡æ•°ï¼‰
- é¨æ‰‹æŒ‡æ•°ãƒ»èª¿æ•™å¸«æŒ‡æ•°
- è¡€çµ±è©•ä¾¡ãƒ»è¡€çµ±ãƒã‚¤ãƒ³ãƒˆ
- ã‚³ãƒ¼ã‚¹é©æ€§ãƒ»è·é›¢é©æ€§
- å±•é–‹äºˆæƒ³ï¼ˆè„šè³ªåˆ†æï¼‰
```

## ğŸ“š å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º

### Phase 0: ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆJRA-VAN + JRDB ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰
- JRA-VANã‹ã‚‰åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
- JRDBã‹ã‚‰ç‹¬è‡ªæŒ‡æ•°ã‚’å–å¾—
- race_id + umaban ã§ãƒãƒ¼ã‚¸
- çµ±åˆCSVã‚’ç”Ÿæˆ

### Phase 1: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
- JRA-VANåŸºæœ¬ç‰¹å¾´é‡ï¼ˆ50å€‹ï¼‰
- **JRDBç‹¬è‡ªæŒ‡æ•°ç‰¹å¾´é‡ï¼ˆ20å€‹è¿½åŠ ï¼‰**
- èŠ/ãƒ€ãƒ¼ãƒˆå¯¾å¿œç‰¹å¾´é‡
- ã‚³ãƒ¼ã‚¹å½¢çŠ¶ç‰¹å¾´é‡

### Phase 2: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™
- 2020-2025å¹´ã®éå»ãƒ‡ãƒ¼ã‚¿
- 10ç«¶é¦¬å ´åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

### Phase 3: äºŒå€¤åˆ†é¡ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
- LightGBMã€10ç«¶é¦¬å ´åˆ¥
- ç›®æ¨™AUC: **0.85ä»¥ä¸Š**

### Phase 4-1: ãƒ©ãƒ³ã‚­ãƒ³ã‚°äºˆæ¸¬
- LightGBM Ranker

### Phase 4-2: å›å¸°äºˆæ¸¬
- LightGBM Regressor

### Phase 5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ
- é‡ã¿: Binary 30%, Ranking 50%, Regression 20%

### Phase 6: é…ä¿¡ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
- **WIN5å¯¾å¿œ**
- Note/ãƒ–ãƒƒã‚«ãƒ¼ã‚º/Twitterç”¨ãƒ†ã‚­ã‚¹ãƒˆ

### Phase 7-10: é«˜åº¦åŒ–
- Greedy Borutaç‰¹å¾´é‡é¸æŠ
- Optunaè‡ªå‹•æœ€é©åŒ–
- KellyåŸºæº–ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³
- ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆROIæ¤œè¨¼ï¼‰

## ğŸ” æœ€åˆã®è³ªå•ãƒ»ç¢ºèªäº‹é …

æ·»ä»˜ã® **JRA_VERSION_COMPLETE_REFERENCE.md** ã‚’ç¢ºèªã—ã€ä»¥ä¸‹ã«ã¤ã„ã¦ææ¡ˆã—ã¦ãã ã•ã„:

### 1. Phase 0ï¼ˆãƒ‡ãƒ¼ã‚¿å–å¾—ï¼‰ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè£…æ–¹é‡
- JRA-VAN SDK ã®ä½¿ã„æ–¹
- JRDB API ã®ä½¿ã„æ–¹
- ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ã®å…·ä½“çš„ãªæ–¹æ³•
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆJRDBæŒ‡æ•°æ¬ ææ™‚ã®å‡¦ç†ï¼‰

### 2. Phase 1ï¼ˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼‰ã®è¨­è¨ˆ
- èŠ/ãƒ€ãƒ¼ãƒˆç‰¹å¾´é‡ã®å…·ä½“çš„ãªå®Ÿè£…
- JRDBç‹¬è‡ªæŒ‡æ•°ã®æ´»ç”¨æ–¹æ³•ï¼ˆIDMã€ã‚¿ã‚¤ãƒ æŒ‡æ•°ã€ãƒšãƒ¼ã‚¹æŒ‡æ•°ãªã©ï¼‰
- ç‰¹å¾´é‡ã®é‡è¦åº¦äºˆæ¸¬

### 3. Phase 6ï¼ˆé…ä¿¡ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼‰ã®WIN5å¯¾å¿œ
- WIN5è²·ã„ç›®ç”Ÿæˆã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- æŒ‡å®š5ãƒ¬ãƒ¼ã‚¹ã®TOP3çµ„ã¿åˆã‚ã›ï¼ˆ3^5 = 243ç‚¹ï¼‰
- æŠ•è³‡é¡ç®¡ç†ï¼ˆKellyåŸºæº–é€£æºï¼‰

## ğŸ“‚ å‚è€ƒãƒ•ã‚¡ã‚¤ãƒ«

æ·»ä»˜ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:
1. `JRA_VERSION_COMPLETE_REFERENCE.md` - å®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ï¼ˆ31 KBï¼‰
2. `JRA_VERSION_INSTRUCTIONS.md` - å®Ÿè£…æŒ‡ç¤ºæ›¸ï¼ˆ14 KBï¼‰

**æ³¨æ„**: æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯æ—¢å­˜GitHubãƒªãƒã‚¸ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ç¢ºèªã§ããªã„ãŸã‚ã€ã™ã¹ã¦ã®é‡è¦ãªã‚³ãƒ¼ãƒ‰å®Ÿè£…ä¾‹ã‚’ä¸Šè¨˜ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã«å«ã‚ã¦ã„ã¾ã™ã€‚

## ğŸš€ é–‹å§‹æº–å‚™

æº–å‚™ãŒæ•´ã£ãŸã‚‰ã€ä»¥ä¸‹ã®é †ã§é€²ã‚ã¾ã—ã‚‡ã†:

1. ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€
2. æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç†è§£
3. JRAç‰ˆã®å…·ä½“çš„ãªè¨­è¨ˆæ–¹é‡ã‚’ææ¡ˆ
4. Phase 0ã®å®Ÿè£…ã‹ã‚‰é–‹å§‹

ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ï¼
```

---

## 10. ã¾ã¨ã‚

### âœ… ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å«ã¾ã‚Œã‚‹æƒ…å ±

1. **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“æ¦‚è¦** - æ§‹é€ ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã€æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
2. **Phase 0ã€œ6 ã®å®Œå…¨å®Ÿè£…ä¾‹** - ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆå¯èƒ½ãªã‚³ãƒ¼ãƒ‰
3. **JRAç‰ˆã§ã®å¤‰æ›´ãƒã‚¤ãƒ³ãƒˆ** - èŠ/ãƒ€ãƒ¼ãƒˆå¯¾å¿œã€WIN5å¯¾å¿œ
4. **JRA-VAN + JRDB ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æˆ¦ç•¥** - ãƒ‡ãƒ¼ã‚¿å–å¾—ã®è©³ç´°è¨­è¨ˆ
5. **æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ** - å³åº§ã«ä½¿ç”¨å¯èƒ½ãªæŒ‡ç¤ºæ–‡

### ğŸ“š å‚è€ƒæƒ…å ±

- **å…ƒãƒªãƒã‚¸ãƒˆãƒª**: https://github.com/aka209859-max/anonymous-keiba-ai
- **ãƒ–ãƒ©ãƒ³ãƒ**: phase0_complete_fix_2026_02_07
- **æœ€æ–°ã‚³ãƒŸãƒƒãƒˆ**: 7281efd

---

**Good Luck with JRA Version Development! ğŸ‡ğŸ¯**
