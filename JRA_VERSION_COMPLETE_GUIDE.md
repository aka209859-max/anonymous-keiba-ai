# ğŸ‡ ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰ç‰ˆAIäºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã®ãŸã‚ã®å®Œå…¨è‡ªå·±å®Œçµå‹æŒ‡ç¤ºæ›¸

**ä½œæˆæ—¥**: 2026å¹´02æœˆ14æ—¥  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.0ï¼ˆæ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œå…¨å¯¾å¿œç‰ˆï¼‰  
**é‡è¦**: ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿ã§é–‹ç™ºã‚’é–‹å§‹ã§ãã‚‹ã‚ˆã†ã€å…¨ã¦ã®å¿…è¦æƒ…å ±ã‚’å«ã‚ã¦ã„ã¾ã™

---

## ğŸ“– ã“ã®æŒ‡ç¤ºæ›¸ã«ã¤ã„ã¦

### ğŸ¯ ç›®çš„

æ—¢å­˜ã®**åœ°æ–¹ç«¶é¦¬AIäºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ **ï¼ˆPhase 0-11å®Œæˆï¼‰ã‚’å‚è€ƒã«ã€**ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰å°‚ç”¨ã®äºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ **ã‚’æ–°è¦æ§‹ç¯‰ã™ã‚‹ã€‚

### âš ï¸ é‡è¦ãªå‰æ

- **æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯GitHubãƒªãƒã‚¸ãƒˆãƒªã®ç›´æ¥å‚ç…§ã¯å›°é›£**
- ã“ã®æŒ‡ç¤ºæ›¸ã«**å…¨ã¦ã®å¿…è¦ãªæƒ…å ±ã‚’å«ã‚ã‚‹**ï¼ˆã‚³ãƒ¼ãƒ‰ä¾‹ã€è¨­è¨ˆæ€æƒ³ã€å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
- æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®å‚ç…§ã¯**è£œè¶³æƒ…å ±ã¨ã—ã¦è¨˜è¼‰**

---

## 1. æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ï¼ˆåœ°æ–¹ç«¶é¦¬ï¼‰ã®å®Œå…¨æ§‹é€ 

### ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
anonymous-keiba-ai/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ phase0_data_acquisition/       # PC-KEIBA PostgreSQLã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
â”‚   â”œâ”€â”€ phase1_feature_engineering/    # 50ç‰¹å¾´é‡ç”Ÿæˆ
â”‚   â”œâ”€â”€ phase3_binary/                 # äºŒå€¤åˆ†é¡ï¼ˆå‡ºèµ°åˆ¤å®šï¼‰
â”‚   â”œâ”€â”€ phase4_ranking/                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°äºˆæ¸¬
â”‚   â”œâ”€â”€ phase4_regression/             # å›å¸°äºˆæ¸¬ï¼ˆã‚¿ã‚¤ãƒ ï¼‰
â”‚   â”œâ”€â”€ phase5_ensemble/               # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ
â”‚   â”œâ”€â”€ phase6_betting/                # é…ä¿¡ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
â”‚   â”œâ”€â”€ phase7_feature_selection/      # Greedy Boruta
â”‚   â”œâ”€â”€ phase8_auto_tuning/            # Optunaæœ€é©åŒ–
â”‚   â”œâ”€â”€ phase9_betting_strategy/       # KellyåŸºæº–
â”‚   â”œâ”€â”€ phase10_backtest/              # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
â”‚   â””â”€â”€ phase11_triple_umatan/         # ãƒˆãƒªãƒ—ãƒ«é¦¬å˜ï¼ˆç‹¬ç«‹ï¼‰
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ binary/{ç«¶é¦¬å ´}_v3_model.txt   # 14ç«¶é¦¬å ´åˆ¥ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ ranking/{ç«¶é¦¬å ´}_model.txt
â”‚   â””â”€â”€ regression/{ç«¶é¦¬å ´}_model.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/{å¹´}/{æœˆ}/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_raw.csv
â”‚   â”œâ”€â”€ features/{å¹´}/{æœˆ}/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_features.csv
â”‚   â””â”€â”€ predictions/
â”‚       â”œâ”€â”€ phase3/temp_{æ—¥ä»˜}_phase3_binary.csv
â”‚       â”œâ”€â”€ phase4_ranking/temp_{æ—¥ä»˜}_phase4_ranking.csv
â”‚       â”œâ”€â”€ phase4_regression/temp_{æ—¥ä»˜}_phase4_regression.csv
â”‚       â””â”€â”€ phase5/temp_{æ—¥ä»˜}_ensemble.csv
â””â”€â”€ predictions/
    â”œâ”€â”€ {ç«¶é¦¬å ´}_{æ—¥ä»˜}_note.txt
    â”œâ”€â”€ {ç«¶é¦¬å ´}_{æ—¥ä»˜}_bookers.txt
    â””â”€â”€ {ç«¶é¦¬å ´}_{æ—¥ä»˜}_tweet.txt
```

### ğŸ”§ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯è©³ç´°

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install pandas numpy scikit-learn lightgbm matplotlib seaborn
pip install optuna scipy psycopg2-binary  # Phase 7-10ç”¨
pip install requests beautifulsoup4 lxml  # Phase 11ç”¨
```

### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ï¼ˆå®Œå…¨ç‰ˆï¼‰

```
[Phase 0] ãƒ‡ãƒ¼ã‚¿å–å¾—
â”œâ”€ å…¥åŠ›: PC-KEIBA PostgreSQLï¼ˆåœ°æ–¹ç«¶é¦¬14å ´ï¼‰
â”œâ”€ å‡¦ç†: SQLã‚¯ã‚¨ãƒªã§éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—
â””â”€ å‡ºåŠ›: data/raw/{å¹´}/{æœˆ}/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_raw.csv
         ã‚«ãƒ©ãƒ : 50å€‹ï¼ˆç€é †ã€é¦¬ç•ªã€é¨æ‰‹ã€èª¿æ•™å¸«ã€é¦¬ä½“é‡ç­‰ï¼‰

â†“

[Phase 1] ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
â”œâ”€ å…¥åŠ›: raw CSV
â”œâ”€ å‡¦ç†: éå»æˆç¸¾ã€é¨æ‰‹æˆç¸¾ã€è¡€çµ±æƒ…å ±ã‹ã‚‰50ç‰¹å¾´é‡ç”Ÿæˆ
â”‚   - prev1_rank, prev2_rank, prev3_rankï¼ˆéå»3èµ°ç€é †ï¼‰
â”‚   - jockey_win_rateï¼ˆé¨æ‰‹å‹ç‡ï¼‰
â”‚   - weight_changeï¼ˆé¦¬ä½“é‡å¢—æ¸›ï¼‰
â”‚   - speed_ratingï¼ˆã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°ï¼‰
â”‚   - æ¬ æå€¤å‡¦ç†: å¹³å‡å€¤/0åŸ‹ã‚
â””â”€ å‡ºåŠ›: data/features/{å¹´}/{æœˆ}/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_features.csv

â†“

[Phase 3] äºŒå€¤åˆ†é¡ï¼ˆå‡ºèµ°åˆ¤å®šï¼‰
â”œâ”€ å…¥åŠ›: features CSV
â”œâ”€ ãƒ¢ãƒ‡ãƒ«: LightGBM Classifierï¼ˆ14ç«¶é¦¬å ´åˆ¥ï¼‰
â”œâ”€ å‡¦ç†: ç«¶èµ°ä¸­æ­¢ã€å¤±æ ¼ã€é™ç€ã‚’é™¤å¤–
â”‚   - binary_probabilityï¼ˆå‡ºèµ°ç¢ºç‡ 0ã€œ1ï¼‰
â”‚   - predicted_classï¼ˆ0 or 1ï¼‰
â””â”€ å‡ºåŠ›: data/predictions/phase3/temp_{æ—¥ä»˜}_phase3_binary.csv
         è©•ä¾¡: AUCå¹³å‡0.77ï¼ˆç¯„å›²0.7459ã€œ0.8275ï¼‰

â†“

[Phase 4-1] ãƒ©ãƒ³ã‚­ãƒ³ã‚°äºˆæ¸¬
â”œâ”€ å…¥åŠ›: features CSV
â”œâ”€ ãƒ¢ãƒ‡ãƒ«: LightGBM Ranker
â”œâ”€ å‡¦ç†: ç€é †ã‚¹ã‚³ã‚¢ç®—å‡ºï¼ˆå°ã•ã„ã»ã©ä¸Šä½ï¼‰
â”‚   - ranking_scoreï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¹ã‚³ã‚¢ï¼‰
â”‚   - predicted_rankï¼ˆäºˆæ¸¬ç€é †ï¼‰
â””â”€ å‡ºåŠ›: data/predictions/phase4_ranking/temp_{æ—¥ä»˜}_phase4_ranking.csv

â†“

[Phase 4-2] å›å¸°äºˆæ¸¬ï¼ˆã‚¿ã‚¤ãƒ ï¼‰
â”œâ”€ å…¥åŠ›: features CSV
â”œâ”€ ãƒ¢ãƒ‡ãƒ«: LightGBM Regressor
â”œâ”€ å‡¦ç†: èµ°è¡Œã‚¿ã‚¤ãƒ äºˆæ¸¬ï¼ˆç§’ï¼‰
â”‚   - predicted_timeï¼ˆäºˆæ¸¬ã‚¿ã‚¤ãƒ ï¼‰
â”‚   - time_rankï¼ˆã‚¿ã‚¤ãƒ é †ä½ï¼‰
â””â”€ å‡ºåŠ›: data/predictions/phase4_regression/temp_{æ—¥ä»˜}_phase4_regression.csv

â†“

[Phase 5] ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ
â”œâ”€ å…¥åŠ›: Phase 3, 4-1, 4-2 ã®çµæœ
â”œâ”€ é‡ã¿: Binary 30%, Ranking 50%, Regression 20%
â”œâ”€ å‡¦ç†: å„ã‚¹ã‚³ã‚¢ã‚’0ã€œ1ã«æ­£è¦åŒ–â†’é‡ã¿ä»˜ã‘åˆè¨ˆ
â”‚   - ensemble_score = 
â”‚     binary_normalized * 0.3 + 
â”‚     ranking_normalized * 0.5 + 
â”‚     regression_normalized * 0.2
â”‚   - final_rankï¼ˆæœ€çµ‚ç€é †äºˆæ¸¬ã€ãƒ¬ãƒ¼ã‚¹ã”ã¨ã«ãƒ©ãƒ³ã‚¯ä»˜ã‘ï¼‰
â””â”€ å‡ºåŠ›: data/predictions/phase5/temp_{æ—¥ä»˜}_ensemble.csv

â†“

[Phase 6] é…ä¿¡ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
â”œâ”€ å…¥åŠ›: ensemble CSV
â”œâ”€ å‡¦ç†: å„ãƒ¬ãƒ¼ã‚¹ã®TOPé¦¬ã¨è²·ã„ç›®ã‚’ç”Ÿæˆ
â”‚   - å˜å‹ãƒ»è¤‡å‹: TOP1, TOP2
â”‚   - é¦¬å˜: TOP2ã®çµ„ã¿åˆã‚ã›ï¼ˆ1â†’2ã€2â†’1ï¼‰
â”‚   - ä¸‰é€£è¤‡: 1ãƒ»2ä½ - 2ãƒ»3ãƒ»4ä½ - 2ãƒ»3ãƒ»4ãƒ»5ãƒ»6ãƒ»7ä½
â””â”€ å‡ºåŠ›: 
    â”œâ”€ predictions/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_note.txtï¼ˆNoteæŠ•ç¨¿ç”¨ï¼‰
    â”œâ”€ predictions/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_bookers.txtï¼ˆãƒ–ãƒƒã‚«ãƒ¼ã‚ºç”¨ï¼‰
    â””â”€ predictions/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_tweet.txtï¼ˆTwitterç”¨ï¼‰
```

---

## 2. é‡è¦ã‚³ãƒ¼ãƒ‰ä¾‹ï¼ˆåœ°æ–¹ç«¶é¦¬ã‚·ã‚¹ãƒ†ãƒ ï¼‰

### Phase 0: ãƒ‡ãƒ¼ã‚¿å–å¾—ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 0: ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆåœ°æ–¹ç«¶é¦¬ç‰ˆï¼‰
PC-KEIBA PostgreSQLã‹ã‚‰éå»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
"""

import psycopg2
import pandas as pd
from datetime import datetime

# ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆåœ°æ–¹14å ´ï¼‰
VENUE_CODE_MAP = {
    30: 'é–€åˆ¥', 35: 'ç››å²¡', 36: 'æ°´æ²¢',
    42: 'æµ¦å’Œ', 43: 'èˆ¹æ©‹', 44: 'å¤§äº•', 45: 'å·å´',
    46: 'é‡‘æ²¢', 47: 'ç¬ æ¾', 48: 'åå¤å±‹',
    50: 'åœ’ç”°', 51: 'å§«è·¯', 54: 'é«˜çŸ¥', 55: 'ä½è³€'
}

def fetch_race_data(venue_code, date):
    """PC-KEIBAã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    conn = psycopg2.connect(
        host='localhost',
        database='pckeiba',
        user='postgres',
        password='your_password'
    )
    
    query = f"""
    SELECT 
        kaisai_nen, kaisai_tsukihi, keibajo_code, race_bango,
        umaban, bamei, kakutei_chakujun,
        kishu_mei, chokyoshi_mei, futan_juryo,
        bataiju, zogen_fugo, zogen_sa,
        tansho_odds, fukusho_odds,
        time_value
    FROM race_results
    WHERE keibajo_code = {venue_code}
      AND kaisai_tsukihi = '{date.replace("-", "")}'
    ORDER BY race_bango, umaban
    """
    
    df = pd.read_sql(query, conn)
    conn.close()
    
    return df

def main(venue_code, date):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    venue_name = VENUE_CODE_MAP.get(venue_code, 'Unknown')
    
    print(f"ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {venue_name} {date}")
    
    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    df = fetch_race_data(venue_code, date)
    
    # ä¿å­˜
    year, month = date[:4], date[5:7]
    date_short = date.replace('-', '')
    output_path = f"data/raw/{year}/{month}/{venue_name}_{date_short}_raw.csv"
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df.to_csv(output_path, index=False, encoding='shift-jis')
    
    print(f"âœ… ä¿å­˜å®Œäº†: {output_path} ({len(df)}ä»¶)")

if __name__ == "__main__":
    venue_code = 43  # èˆ¹æ©‹
    date = "2026-02-14"
    main(venue_code, date)
```

### Phase 1: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 1: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆåœ°æ–¹ç«¶é¦¬ç‰ˆï¼‰
50ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
"""

import pandas as pd
import numpy as np

def create_features(df):
    """ç‰¹å¾´é‡ç”Ÿæˆ"""
    
    # 1. éå»æˆç¸¾ç‰¹å¾´é‡
    df['prev1_rank'] = df.groupby('é¦¬ç•ª')['ç€é †'].shift(1).fillna(0)
    df['prev2_rank'] = df.groupby('é¦¬ç•ª')['ç€é †'].shift(2).fillna(0)
    df['prev3_rank'] = df.groupby('é¦¬ç•ª')['ç€é †'].shift(3).fillna(0)
    
    # 2. é¨æ‰‹æˆç¸¾ç‰¹å¾´é‡
    jockey_stats = df.groupby('é¨æ‰‹å').agg({
        'ç€é †': lambda x: (x <= 3).mean()  # 3ç€ä»¥å†…ç‡
    }).rename(columns={'ç€é †': 'jockey_win_rate'})
    df = df.merge(jockey_stats, left_on='é¨æ‰‹å', right_index=True, how='left')
    
    # 3. é¦¬ä½“é‡é–¢é€£
    df['weight_change'] = df.groupby('é¦¬ç•ª')['é¦¬ä½“é‡'].diff().fillna(0)
    
    # 4. ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    df['speed_rating'] = 100 - (df['ã‚¿ã‚¤ãƒ '] - df['ã‚¿ã‚¤ãƒ '].min()) / df['ã‚¿ã‚¤ãƒ '].std()
    
    # 5. ã‚ªãƒƒã‚ºé–¢é€£
    df['odds_rank'] = df.groupby('ãƒ¬ãƒ¼ã‚¹ç•ªå·')['å˜å‹ã‚ªãƒƒã‚º'].rank()
    
    # æ¬ æå€¤å‡¦ç†
    df.fillna(0, inplace=True)
    
    return df

def main(raw_csv_path, output_csv_path):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print(f"ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹: {raw_csv_path}")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_csv(raw_csv_path, encoding='shift-jis')
    
    # ç‰¹å¾´é‡ç”Ÿæˆ
    df_features = create_features(df)
    
    # ä¿å­˜
    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)
    df_features.to_csv(output_csv_path, index=False, encoding='shift-jis')
    
    print(f"âœ… ä¿å­˜å®Œäº†: {output_csv_path} ({len(df_features)}ä»¶)")

if __name__ == "__main__":
    raw_csv_path = "data/raw/2026/02/èˆ¹æ©‹_20260214_raw.csv"
    output_csv_path = "data/features/2026/02/èˆ¹æ©‹_20260214_features.csv"
    main(raw_csv_path, output_csv_path)
```

### Phase 5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆï¼ˆåœ°æ–¹ç«¶é¦¬ç‰ˆï¼‰
Binary 30%, Ranking 50%, Regression 20%
"""

import pandas as pd
import numpy as np

def normalize_score(series, ascending=True):
    """0ã€œ1ã«æ­£è¦åŒ–"""
    min_val, max_val = series.min(), series.max()
    if max_val == min_val:
        return pd.Series([0.5] * len(series), index=series.index)
    
    if ascending:
        # å°ã•ã„ã»ã©è‰¯ã„ï¼ˆã‚¿ã‚¤ãƒ ï¼‰
        return 1.0 - (series - min_val) / (max_val - min_val)
    else:
        # å¤§ãã„ã»ã©è‰¯ã„ï¼ˆç¢ºç‡ï¼‰
        return (series - min_val) / (max_val - min_val)

def ensemble_predictions(binary_csv, ranking_csv, regression_csv, output_csv):
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ"""
    
    # é‡ã¿è¨­å®š
    WEIGHT_BINARY = 0.3
    WEIGHT_RANKING = 0.5
    WEIGHT_REGRESSION = 0.2
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df_binary = pd.read_csv(binary_csv, encoding='shift-jis')
    df_ranking = pd.read_csv(ranking_csv, encoding='shift-jis')
    df_regression = pd.read_csv(regression_csv, encoding='shift-jis')
    
    # ãƒãƒ¼ã‚¸
    df = df_binary.merge(
        df_ranking[['race_id', 'umaban', 'ranking_score', 'predicted_rank']],
        on=['race_id', 'umaban'], how='inner'
    ).merge(
        df_regression[['race_id', 'umaban', 'predicted_time', 'time_rank']],
        on=['race_id', 'umaban'], how='inner'
    )
    
    # ãƒ¬ãƒ¼ã‚¹ã”ã¨ã«æ­£è¦åŒ–
    df['binary_normalized'] = df.groupby('race_id')['binary_probability'].transform(
        lambda x: normalize_score(x, ascending=False)
    )
    df['ranking_normalized'] = df.groupby('race_id')['ranking_score'].transform(
        lambda x: normalize_score(x, ascending=False)
    )
    df['regression_normalized'] = df.groupby('race_id')['predicted_time'].transform(
        lambda x: normalize_score(x, ascending=True)
    )
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚¹ã‚³ã‚¢è¨ˆç®—
    df['ensemble_score'] = (
        df['binary_normalized'] * WEIGHT_BINARY +
        df['ranking_normalized'] * WEIGHT_RANKING +
        df['regression_normalized'] * WEIGHT_REGRESSION
    )
    
    # æœ€çµ‚é †ä½æ±ºå®š
    df['final_rank'] = df.groupby('race_id')['ensemble_score'].rank(
        ascending=False, method='min'
    ).astype(int)
    
    # ä¿å­˜
    df.to_csv(output_csv, index=False, encoding='shift-jis')
    print(f"âœ… ä¿å­˜å®Œäº†: {output_csv}")

if __name__ == "__main__":
    binary_csv = "data/predictions/phase3/temp_20260214_phase3_binary.csv"
    ranking_csv = "data/predictions/phase4_ranking/temp_20260214_phase4_ranking.csv"
    regression_csv = "data/predictions/phase4_regression/temp_20260214_phase4_regression.csv"
    output_csv = "data/predictions/phase5/temp_20260214_ensemble.csv"
    
    ensemble_predictions(binary_csv, ranking_csv, regression_csv, output_csv)
```

---

## 3. åœ°æ–¹ç«¶é¦¬ã¨JRAã®å®Œå…¨æ¯”è¼ƒè¡¨

### ç«¶é¦¬å ´

| é …ç›® | åœ°æ–¹ç«¶é¦¬ | JRA |
|------|---------|-----|
| ç«¶é¦¬å ´æ•° | 14å ´ | 10å ´ |
| ç«¶é¦¬å ´å | é–€åˆ¥ã€ç››å²¡ã€æ°´æ²¢ã€æµ¦å’Œã€èˆ¹æ©‹ã€å¤§äº•ã€å·å´ã€é‡‘æ²¢ã€ç¬ æ¾ã€åå¤å±‹ã€åœ’ç”°ã€å§«è·¯ã€é«˜çŸ¥ã€ä½è³€ | **æœ­å¹Œã€å‡½é¤¨ã€ç¦å³¶ã€æ–°æ½Ÿã€æ±äº¬ã€ä¸­å±±ã€ä¸­äº¬ã€äº¬éƒ½ã€é˜ªç¥ã€å°å€‰** |
| ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ | 30, 35, 36, 42, 43, 44, 45, 46, 47, 48, 50, 51, 54, 55 | **01, 02, 03, 04, 05, 06, 07, 08, 09, 10** |

### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹

| é …ç›® | åœ°æ–¹ç«¶é¦¬ | JRA | å®Ÿè£…æ–¹é‡ |
|------|---------|-----|----------|
| ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ | PC-KEIBA PostgreSQL | **JRA-VAN Data Lab** ã¾ãŸã¯ netkeiba.com | JRA-VANæ¨å¥¨ï¼ˆæœ‰æ–™ã ãŒä¿¡é ¼æ€§é«˜ã„ï¼‰ |
| ãƒ‡ãƒ¼ã‚¿å½¢å¼ | SQLã‚¯ã‚¨ãƒªâ†’CSV | **SDKçµŒç”±**â†’CSV or ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°â†’CSV | SDKã¾ãŸã¯ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° |
| ãƒ‡ãƒ¼ã‚¿é‡ | ç´„68ä¸‡ä»¶ï¼ˆ2020-2025ï¼‰ | ç´„æ•°ç™¾ä¸‡ä»¶ï¼ˆ2020-2025ï¼‰ | åŒç­‰ã®å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ |
| æ›´æ–°é »åº¦ | é–‹å‚¬æ—¥ç¿Œæ—¥ | **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ **ï¼ˆJRA-VANï¼‰ | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾å¿œæ¤œè¨ |

### ãƒ¬ãƒ¼ã‚¹æ§‹æˆ

| é …ç›® | åœ°æ–¹ç«¶é¦¬ | JRA | å®Ÿè£…ã¸ã®å½±éŸ¿ |
|------|---------|-----|--------------|
| 1æ—¥ã®ãƒ¬ãƒ¼ã‚¹æ•° | 10ã€œ12R | 12Rï¼ˆåœŸæ—¥ç¥ï¼‰ | åŒç­‰ã®å‡¦ç† |
| å‡ºèµ°é ­æ•° | 8ã€œ16é ­ | **æœ€å¤§18é ­** | ãƒ•ãƒ«ã‚²ãƒ¼ãƒˆ18é ­å¯¾å¿œ |
| é¦¬å ´ç¨®åˆ¥ | **ãƒ€ãƒ¼ãƒˆä¸»ä½“** | **èŠãƒ»ãƒ€ãƒ¼ãƒˆãƒ»éšœå®³** | âœ… **é‡è¦**: track_typeç‰¹å¾´é‡è¿½åŠ  |
| ã‚³ãƒ¼ã‚¹å½¢æ…‹ | å°å›ã‚Šå¤šã„ | å¤§å›ã‚Šã€ç›´ç·šé•·ã„ | âœ… **é‡è¦**: ã‚³ãƒ¼ã‚¹ç‰¹æ€§ç‰¹å¾´é‡è¿½åŠ  |

### ç‰¹å¾´é‡ã®é•ã„

| ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒª | åœ°æ–¹ç«¶é¦¬ | JRA | JRAç‰ˆã§ã®å¯¾å¿œ |
|---------------|---------|-----|--------------|
| é¦¬å ´çŠ¶æ…‹ | ãƒ€ãƒ¼ãƒˆï¼ˆè‰¯ã€ç¨é‡ã€é‡ã€ä¸è‰¯ï¼‰ | **èŠãƒ»ãƒ€ãƒ¼ãƒˆãƒ»éšœå®³** Ã— ï¼ˆè‰¯ã€ç¨é‡ã€é‡ã€ä¸è‰¯ï¼‰ | `track_type`ï¼ˆèŠ/ãƒ€ãƒ¼ãƒˆ/éšœå®³ï¼‰ã‚«ãƒ©ãƒ è¿½åŠ  |
| ã‚³ãƒ¼ã‚¹å½¢çŠ¶ | - | **å³å›ã‚Š/å·¦å›ã‚Šã€ç›´ç·šè·é›¢** | `track_direction`, `straight_length` è¿½åŠ  |
| é–‹å‚¬æ™‚æœŸ | - | **æ˜¥ãƒ»å¤ãƒ»ç§‹ãƒ»å†¬**ï¼ˆé¦¬å ´çŠ¶æ…‹ãŒå­£ç¯€ã§å¤‰å‹•ï¼‰ | `season` ã‚«ãƒ©ãƒ è¿½åŠ  |
| ã‚°ãƒ¬ãƒ¼ãƒ‰ | Jpn1, Jpn2, Jpn3 | **G1, G2, G3, ãƒªã‚¹ãƒ†ãƒƒãƒ‰** | `grade_class` ã‚«ãƒ©ãƒ è¿½åŠ  |
| è³é‡‘ | æ•°ç™¾ä¸‡ã€œæ•°åƒä¸‡å†† | **æ•°åƒä¸‡ã€œæ•°å„„å††** | `prize_money` ã‚«ãƒ©ãƒ è¿½åŠ  |

### é¦¬åˆ¸ç¨®é¡

| é¦¬åˆ¸ | åœ°æ–¹ç«¶é¦¬ | JRA | JRAç‰ˆã§ã®å¯¾å¿œ |
|------|---------|-----|--------------|
| å˜å‹ãƒ»è¤‡å‹ | âœ… | âœ… | åŒã˜ |
| é¦¬é€£ãƒ»é¦¬å˜ | âœ… | âœ… | åŒã˜ |
| 3é€£è¤‡ãƒ»3é€£å˜ | âœ… | âœ… | åŒã˜ |
| ãƒ¯ã‚¤ãƒ‰ | âœ… | âœ… | åŒã˜ |
| WIN5 | âŒ | âœ… | âœ… **Phase 6ã§æ–°æ©Ÿèƒ½è¿½åŠ ** |
| ãƒˆãƒªãƒ—ãƒ«é¦¬å˜ | âœ…ï¼ˆSPAT4 LOTOï¼‰ | âŒ | JRAç‰ˆã§ã¯ä¸è¦ |

---

## 4. JRAç‰ˆã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆï¼ˆå®Œå…¨ç‰ˆï¼‰

### ğŸ“¦ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
jra-keiba-ai/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ phase0_data_acquisition/
â”‚   â”‚   â””â”€â”€ extract_race_data_jra.py       # JRA-VANå¯¾å¿œ
â”‚   â”œâ”€â”€ phase1_feature_engineering/
â”‚   â”‚   â””â”€â”€ prepare_features_jra.py        # èŠãƒ»ãƒ€ãƒ¼ãƒˆç‰¹å¾´é‡è¿½åŠ 
â”‚   â”œâ”€â”€ phase3_binary/
â”‚   â”‚   â””â”€â”€ predict_phase3_inference_jra.py # 10ç«¶é¦¬å ´å¯¾å¿œ
â”‚   â”œâ”€â”€ phase4_ranking/
â”‚   â”‚   â””â”€â”€ predict_phase4_ranking_inference_jra.py
â”‚   â”œâ”€â”€ phase4_regression/
â”‚   â”‚   â””â”€â”€ predict_phase4_regression_inference_jra.py
â”‚   â”œâ”€â”€ phase5_ensemble/
â”‚   â”‚   â””â”€â”€ ensemble_predictions_jra.py
â”‚   â”œâ”€â”€ phase6_betting/
â”‚   â”‚   â”œâ”€â”€ generate_distribution_note_jra.py
â”‚   â”‚   â”œâ”€â”€ generate_distribution_bookers_jra.py
â”‚   â”‚   â”œâ”€â”€ generate_distribution_tweet_jra.py
â”‚   â”‚   â””â”€â”€ generate_win5_tickets.py      # WIN5å°‚ç”¨
â”‚   â”œâ”€â”€ phase7_feature_selection/
â”‚   â”œâ”€â”€ phase8_auto_tuning/
â”‚   â”œâ”€â”€ phase9_betting_strategy/
â”‚   â””â”€â”€ phase10_backtest/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ binary/
â”‚   â”‚   â”œâ”€â”€ æœ­å¹Œ_v1_model.txt
â”‚   â”‚   â”œâ”€â”€ å‡½é¤¨_v1_model.txt
â”‚   â”‚   â”œâ”€â”€ ... (10ç«¶é¦¬å ´)
â”‚   â”œâ”€â”€ ranking/
â”‚   â””â”€â”€ regression/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/{å¹´}/{æœˆ}/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_raw.csv
â”‚   â”œâ”€â”€ features/{å¹´}/{æœˆ}/{ç«¶é¦¬å ´}_{æ—¥ä»˜}_features.csv
â”‚   â””â”€â”€ predictions/
â””â”€â”€ docs/
    â””â”€â”€ README.md
```

### ğŸ†• JRAç‰ˆã®è¿½åŠ ç‰¹å¾´é‡ï¼ˆåˆè¨ˆ70ç‰¹å¾´é‡ï¼‰

#### æ—¢å­˜ç‰¹å¾´é‡ï¼ˆåœ°æ–¹ç«¶é¦¬ã‹ã‚‰æµç”¨ã€50å€‹ï¼‰
1. prev1_rank, prev2_rank, prev3_rank
2. jockey_win_rate
3. weight_change
4. speed_rating
5. odds_rank
6. ... (ä»–45å€‹)

#### æ–°è¦ç‰¹å¾´é‡ï¼ˆJRAç‰¹æœ‰ã€20å€‹ï¼‰

```python
# 1. é¦¬å ´ç¨®åˆ¥é–¢é€£ï¼ˆ5å€‹ï¼‰
track_type_èŠ = 1 if track_type == 'èŠ' else 0
track_type_ãƒ€ãƒ¼ãƒˆ = 1 if track_type == 'ãƒ€ãƒ¼ãƒˆ' else 0
track_type_éšœå®³ = 1 if track_type == 'éšœå®³' else 0
turf_win_rate = èŠã‚³ãƒ¼ã‚¹ã§ã®å‹ç‡
dirt_win_rate = ãƒ€ãƒ¼ãƒˆã‚³ãƒ¼ã‚¹ã§ã®å‹ç‡

# 2. ã‚³ãƒ¼ã‚¹ç‰¹æ€§é–¢é€£ï¼ˆ5å€‹ï¼‰
track_direction = 1 if 'å³' else 0  # å³å›ã‚Š/å·¦å›ã‚Š
straight_length = ç›´ç·šè·é›¢ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰
course_category = å¹³å¦/å‚/æ€¥å‚ï¼ˆOne-Hot 3å€‹ï¼‰

# 3. é–‹å‚¬æ™‚æœŸé–¢é€£ï¼ˆ5å€‹ï¼‰
season_spring, season_summer, season_autumn, season_winter (One-Hot)
opening_week = é–‹å‚¬é€±ï¼ˆ1ã€œ5é€±ï¼‰

# 4. JRAç‰¹æœ‰æƒ…å ±ï¼ˆ5å€‹ï¼‰
grade_class = G1/G2/G3/ä¸€èˆ¬/æœªå‹åˆ©ï¼ˆOne-Hot 5å€‹ï¼‰
prize_money = è³é‡‘é¡ï¼ˆå††ï¼‰
field_size = å‡ºèµ°é ­æ•°ï¼ˆ8ã€œ18ï¼‰
post_position = æ é †ï¼ˆ1ã€œ8ï¼‰
track_condition_num = é¦¬å ´çŠ¶æ…‹ï¼ˆè‰¯=1, ç¨é‡=2, é‡=3, ä¸è‰¯=4ï¼‰
```

---

## 5. å®Ÿè£…æ‰‹é †ï¼ˆå®Œå…¨ç‰ˆï¼‰

### Step 1: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# æ–°è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir jra-keiba-ai
cd jra-keiba-ai

# GitåˆæœŸåŒ–
git init

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
mkdir -p scripts/{phase0_data_acquisition,phase1_feature_engineering,phase3_binary,phase4_ranking,phase4_regression,phase5_ensemble,phase6_betting,phase7_feature_selection,phase8_auto_tuning,phase9_betting_strategy,phase10_backtest}
mkdir -p models/{binary,ranking,regression}
mkdir -p data/{raw,features,predictions,training}
mkdir -p docs

# READMEä½œæˆ
cat > README.md << 'EOF'
# JRA Keiba AI - ä¸­å¤®ç«¶é¦¬AIäºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ 

ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰ã«ç‰¹åŒ–ã—ãŸå®šé‡çš„å–å¼•ã‚¨ãƒ³ã‚¸ãƒ³

## å¯¾è±¡ç«¶é¦¬å ´
æœ­å¹Œã€å‡½é¤¨ã€ç¦å³¶ã€æ–°æ½Ÿã€æ±äº¬ã€ä¸­å±±ã€ä¸­äº¬ã€äº¬éƒ½ã€é˜ªç¥ã€å°å€‰ï¼ˆ10å ´ï¼‰

## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
- Python 3.14
- LightGBM
- JRA-VAN Data Lab ã¾ãŸã¯ netkeiba.com
- Optuna, KellyåŸºæº–

## Phaseæ§‹æˆ
- Phase 0: ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆJRA-VANå¯¾å¿œï¼‰
- Phase 1: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆ70ç‰¹å¾´é‡ï¼‰
- Phase 3-5: äºˆæ¸¬ãƒ»ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
- Phase 6: é…ä¿¡ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆWIN5å¯¾å¿œï¼‰
- Phase 7-10: é«˜åº¦åŒ–æ©Ÿèƒ½
EOF
```

### Step 2: Phase 0å®Ÿè£…ï¼ˆJRA-VANå¯¾å¿œï¼‰

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³1: JRA-VAN Data Labï¼ˆæ¨å¥¨ï¼‰

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 0: JRA-VAN Data Labã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
"""

# æ³¨æ„: JRA-VAN SDKã¯å®Ÿéš›ã®SDKãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§
# ã“ã“ã§ã¯æ“¬ä¼¼ã‚³ãƒ¼ãƒ‰ã‚’ç¤ºã—ã¾ã™

import pandas as pd
from datetime import datetime
import os

# JRAç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
JRA_VENUE_CODE_MAP = {
    1: 'æœ­å¹Œ', 2: 'å‡½é¤¨', 3: 'ç¦å³¶', 4: 'æ–°æ½Ÿ',
    5: 'æ±äº¬', 6: 'ä¸­å±±', 7: 'ä¸­äº¬', 8: 'äº¬éƒ½',
    9: 'é˜ªç¥', 10: 'å°å€‰'
}

def fetch_jra_race_data(venue_code, date):
    """JRA-VANã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    
    # JRA-VAN SDKã‚’ä½¿ç”¨ï¼ˆå®Ÿéš›ã®APIå‘¼ã³å‡ºã—ï¼‰
    # ä¾‹: jravan.get_race_results()
    
    # ãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼ˆå®Ÿéš›ã¯SDKçµŒç”±ã§å–å¾—ï¼‰
    data = {
        'é–‹å‚¬å¹´': [],
        'é–‹å‚¬æœˆæ—¥': [],
        'ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰': [],
        'ãƒ¬ãƒ¼ã‚¹ç•ªå·': [],
        'é¦¬ç•ª': [],
        'é¦¬å': [],
        'ç¢ºå®šç€é †': [],
        'é¨æ‰‹å': [],
        'èª¿æ•™å¸«å': [],
        'è² æ‹…é‡é‡': [],
        'é¦¬ä½“é‡': [],
        'é¦¬ä½“é‡å¢—æ¸›': [],
        'å˜å‹ã‚ªãƒƒã‚º': [],
        'è¤‡å‹ã‚ªãƒƒã‚º': [],
        'ã‚¿ã‚¤ãƒ ': [],
        'é¦¬å ´ç¨®åˆ¥': [],  # èŠ/ãƒ€ãƒ¼ãƒˆ/éšœå®³
        'é¦¬å ´çŠ¶æ…‹': [],  # è‰¯/ç¨é‡/é‡/ä¸è‰¯
        'ã‚³ãƒ¼ã‚¹è·é›¢': [],
        'ã‚³ãƒ¼ã‚¹å½¢çŠ¶': [],  # å³/å·¦
        'ã‚°ãƒ¬ãƒ¼ãƒ‰': [],  # G1/G2/G3/ä¸€èˆ¬
        'è³é‡‘': []
    }
    
    df = pd.DataFrame(data)
    return df

def main(venue_code, date):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    venue_name = JRA_VENUE_CODE_MAP.get(venue_code, 'Unknown')
    
    print(f"[Phase 0] ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {venue_name} {date}")
    
    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    df = fetch_jra_race_data(venue_code, date)
    
    # ä¿å­˜
    year, month = date[:4], date[5:7]
    date_short = date.replace('-', '')
    output_path = f"data/raw/{year}/{month}/{venue_name}_{date_short}_raw.csv"
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df.to_csv(output_path, index=False, encoding='utf-8')
    
    print(f"âœ… ä¿å­˜å®Œäº†: {output_path} ({len(df)}ä»¶)")

if __name__ == "__main__":
    venue_code = 5  # æ±äº¬
    date = "2026-02-16"  # æ—¥æ›œæ—¥
    main(venue_code, date)
```

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³2: netkeiba.comã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 0: netkeiba.comã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆä»£æ›¿æ¡ˆï¼‰
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

def scrape_netkeiba_race(race_id):
    """netkeibaã‹ã‚‰1ãƒ¬ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    
    url = f"https://race.netkeiba.com/race/result.html?race_id={race_id}"
    
    # User-Agentè¨­å®šï¼ˆå¿…é ˆï¼‰
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    response = requests.get(url, headers=headers)
    response.encoding = response.apparent_encoding
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # ç€é †è¡¨ã‚’å–å¾—ï¼ˆå®Ÿéš›ã®DOMæ§‹é€ ã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
    table = soup.find('table', class_='race_table_01')
    
    data = []
    for row in table.find_all('tr')[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
        cols = row.find_all('td')
        if len(cols) > 0:
            data.append({
                'ç€é †': cols[0].text.strip(),
                'æ ç•ª': cols[1].text.strip(),
                'é¦¬ç•ª': cols[2].text.strip(),
                'é¦¬å': cols[3].text.strip(),
                'é¨æ‰‹': cols[6].text.strip(),
                'å˜å‹ã‚ªãƒƒã‚º': cols[12].text.strip(),
                # ... ä»–ã®ã‚«ãƒ©ãƒ 
            })
    
    df = pd.DataFrame(data)
    
    # ã‚¢ã‚¯ã‚»ã‚¹é »åº¦åˆ¶é™ï¼ˆé‡è¦ï¼ï¼‰
    time.sleep(1)
    
    return df

def main(venue_code, date, num_races=12):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # race_idã®ç”Ÿæˆï¼ˆä¾‹: 202602051101 = 2026å¹´ æ±äº¬5å› 1æ—¥ç›® 1Rï¼‰
    # å®Ÿéš›ã®race_idç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã¯è¦èª¿æ•´
    
    all_data = []
    for race_num in range(1, num_races + 1):
        race_id = f"{date.replace('-', '')}{venue_code:02d}{race_num:02d}"
        
        print(f"å–å¾—ä¸­: ãƒ¬ãƒ¼ã‚¹{race_num}R (race_id: {race_id})")
        df = scrape_netkeiba_race(race_id)
        all_data.append(df)
    
    # çµ±åˆ
    df_all = pd.concat(all_data, ignore_index=True)
    
    # ä¿å­˜
    output_path = f"data/raw/{date[:4]}/{date[5:7]}/æ±äº¬_{date.replace('-', '')}_raw.csv"
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df_all.to_csv(output_path, index=False, encoding='utf-8')
    
    print(f"âœ… ä¿å­˜å®Œäº†: {output_path} ({len(df_all)}ä»¶)")

if __name__ == "__main__":
    venue_code = 5  # æ±äº¬
    date = "2026-02-16"
    main(venue_code, date)
```

### Step 3: Phase 1å®Ÿè£…ï¼ˆèŠãƒ»ãƒ€ãƒ¼ãƒˆç‰¹å¾´é‡è¿½åŠ ï¼‰

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 1: JRAç‰ˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
æ—¢å­˜50ç‰¹å¾´é‡ + JRAç‰¹æœ‰20ç‰¹å¾´é‡ = è¨ˆ70ç‰¹å¾´é‡
"""

import pandas as pd
import numpy as np

def create_jra_features(df):
    """JRAç‰¹æœ‰ã®ç‰¹å¾´é‡ã‚’è¿½åŠ """
    
    # === æ—¢å­˜ç‰¹å¾´é‡ï¼ˆåœ°æ–¹ç«¶é¦¬ã¨åŒã˜ï¼‰ ===
    # éå»æˆç¸¾
    df['prev1_rank'] = df.groupby('é¦¬ç•ª')['ç€é †'].shift(1).fillna(0)
    df['prev2_rank'] = df.groupby('é¦¬ç•ª')['ç€é †'].shift(2).fillna(0)
    df['prev3_rank'] = df.groupby('é¦¬ç•ª')['ç€é †'].shift(3).fillna(0)
    
    # é¨æ‰‹æˆç¸¾
    jockey_stats = df.groupby('é¨æ‰‹å').agg({
        'ç€é †': lambda x: (x <= 3).mean()
    }).rename(columns={'ç€é †': 'jockey_win_rate'})
    df = df.merge(jockey_stats, left_on='é¨æ‰‹å', right_index=True, how='left')
    
    # é¦¬ä½“é‡
    df['weight_change'] = df.groupby('é¦¬ç•ª')['é¦¬ä½“é‡'].diff().fillna(0)
    
    # === JRAç‰¹æœ‰ç‰¹å¾´é‡ï¼ˆæ–°è¦è¿½åŠ ï¼‰ ===
    
    # 1. é¦¬å ´ç¨®åˆ¥ï¼ˆOne-Hotï¼‰
    df['track_type_èŠ'] = (df['é¦¬å ´ç¨®åˆ¥'] == 'èŠ').astype(int)
    df['track_type_ãƒ€ãƒ¼ãƒˆ'] = (df['é¦¬å ´ç¨®åˆ¥'] == 'ãƒ€ãƒ¼ãƒˆ').astype(int)
    df['track_type_éšœå®³'] = (df['é¦¬å ´ç¨®åˆ¥'] == 'éšœå®³').astype(int)
    
    # 2. é¦¬å ´åˆ¥å‹ç‡
    turf_stats = df[df['é¦¬å ´ç¨®åˆ¥'] == 'èŠ'].groupby('é¦¬ç•ª').agg({
        'ç€é †': lambda x: (x == 1).mean()
    }).rename(columns={'ç€é †': 'turf_win_rate'})
    df = df.merge(turf_stats, left_on='é¦¬ç•ª', right_index=True, how='left', suffixes=('', '_turf'))
    
    dirt_stats = df[df['é¦¬å ´ç¨®åˆ¥'] == 'ãƒ€ãƒ¼ãƒˆ'].groupby('é¦¬ç•ª').agg({
        'ç€é †': lambda x: (x == 1).mean()
    }).rename(columns={'ç€é †': 'dirt_win_rate'})
    df = df.merge(dirt_stats, left_on='é¦¬ç•ª', right_index=True, how='left', suffixes=('', '_dirt'))
    
    # 3. ã‚³ãƒ¼ã‚¹å½¢çŠ¶
    df['track_direction'] = (df['ã‚³ãƒ¼ã‚¹å½¢çŠ¶'] == 'å³').astype(int)
    df['straight_length'] = df['ç›´ç·šè·é›¢']  # ãƒ¡ãƒ¼ãƒˆãƒ«
    
    # 4. é–‹å‚¬æ™‚æœŸï¼ˆå­£ç¯€ï¼‰
    df['é–‹å‚¬æœˆ'] = pd.to_datetime(df['é–‹å‚¬æœˆæ—¥'], format='%Y%m%d').dt.month
    df['season_spring'] = df['é–‹å‚¬æœˆ'].isin([3, 4, 5]).astype(int)
    df['season_summer'] = df['é–‹å‚¬æœˆ'].isin([6, 7, 8]).astype(int)
    df['season_autumn'] = df['é–‹å‚¬æœˆ'].isin([9, 10, 11]).astype(int)
    df['season_winter'] = df['é–‹å‚¬æœˆ'].isin([12, 1, 2]).astype(int)
    
    # 5. ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼ˆOne-Hotï¼‰
    df['grade_G1'] = (df['ã‚°ãƒ¬ãƒ¼ãƒ‰'] == 'G1').astype(int)
    df['grade_G2'] = (df['ã‚°ãƒ¬ãƒ¼ãƒ‰'] == 'G2').astype(int)
    df['grade_G3'] = (df['ã‚°ãƒ¬ãƒ¼ãƒ‰'] == 'G3').astype(int)
    df['grade_listed'] = (df['ã‚°ãƒ¬ãƒ¼ãƒ‰'] == 'Listed').astype(int)
    df['grade_normal'] = (df['ã‚°ãƒ¬ãƒ¼ãƒ‰'].isnull() | (df['ã‚°ãƒ¬ãƒ¼ãƒ‰'] == 'ä¸€èˆ¬')).astype(int)
    
    # 6. è³é‡‘ãƒ»å‡ºèµ°é ­æ•°
    df['prize_money'] = df['è³é‡‘']
    df['field_size'] = df.groupby('ãƒ¬ãƒ¼ã‚¹ç•ªå·')['é¦¬ç•ª'].transform('count')
    df['post_position'] = df['æ ç•ª']
    
    # 7. é¦¬å ´çŠ¶æ…‹ï¼ˆæ•°å€¤åŒ–ï¼‰
    condition_map = {'è‰¯': 1, 'ç¨é‡': 2, 'é‡': 3, 'ä¸è‰¯': 4}
    df['track_condition_num'] = df['é¦¬å ´çŠ¶æ…‹'].map(condition_map).fillna(1)
    
    # æ¬ æå€¤å‡¦ç†
    df.fillna(0, inplace=True)
    
    return df

def main(raw_csv_path, output_csv_path):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print(f"[Phase 1] ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹: {raw_csv_path}")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_csv(raw_csv_path, encoding='utf-8')
    
    # ç‰¹å¾´é‡ç”Ÿæˆ
    df_features = create_jra_features(df)
    
    # ä¿å­˜
    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)
    df_features.to_csv(output_csv_path, index=False, encoding='utf-8')
    
    print(f"âœ… ä¿å­˜å®Œäº†: {output_csv_path} ({len(df_features)}ä»¶ã€{len(df_features.columns)}ç‰¹å¾´é‡)")

if __name__ == "__main__":
    raw_csv_path = "data/raw/2026/02/æ±äº¬_20260216_raw.csv"
    output_csv_path = "data/features/2026/02/æ±äº¬_20260216_features.csv"
    main(raw_csv_path, output_csv_path)
```

### Step 4: Phase 3-5å®Ÿè£…ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã»ã¼æµç”¨ï¼‰

**Phase 3-5ã¯åœ°æ–¹ç«¶é¦¬ç‰ˆã¨ã»ã¼åŒã˜**ãŸã‚ã€ä»¥ä¸‹ã®å¤‰æ›´ã®ã¿å®Ÿæ–½:

1. ãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›´: `_jra.py` ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹è¿½åŠ 
2. ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹å¤‰æ›´: `models/binary/{JRAç«¶é¦¬å ´}_v1_model.txt`
3. ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°æ›´æ–°: 14å ´â†’10å ´

### Step 5: Phase 6å®Ÿè£…ï¼ˆWIN5å¯¾å¿œï¼‰

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 6: WIN5è²·ã„ç›®ç”Ÿæˆï¼ˆJRAå°‚ç”¨ï¼‰
"""

import pandas as pd
from itertools import product

def generate_win5_tickets(ensemble_csv, target_races=[8, 9, 10, 11, 12]):
    """
    WIN5è²·ã„ç›®ç”Ÿæˆ
    æŒ‡å®š5ãƒ¬ãƒ¼ã‚¹ã®æœ¬å‘½é¦¬ï¼ˆTOP3ï¼‰ã‚’çµ„ã¿åˆã‚ã›
    """
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_csv(ensemble_csv, encoding='utf-8')
    
    # å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã®ã¿æŠ½å‡º
    df_target = df[df['race_bango'].isin(target_races)]
    
    # å„ãƒ¬ãƒ¼ã‚¹ã®TOP3é¦¬ã‚’å–å¾—
    top_horses = {}
    for race_num in target_races:
        race_data = df_target[df_target['race_bango'] == race_num]
        top3 = race_data.nsmallest(3, 'final_rank')['umaban'].tolist()
        top_horses[race_num] = top3
    
    # WIN5ã®çµ„ã¿åˆã‚ã›ç”Ÿæˆ
    combinations = list(product(*[top_horses[r] for r in target_races]))
    
    # è³¼å…¥ç‚¹æ•°ã¨æŠ•è³‡é¡
    num_tickets = len(combinations)
    total_cost = num_tickets * 100  # 1ç‚¹100å††
    
    print(f"WIN5è²·ã„ç›®")
    print(f"å¯¾è±¡ãƒ¬ãƒ¼ã‚¹: ç¬¬{target_races[0]}R ã€œ ç¬¬{target_races[-1]}R")
    print(f"è³¼å…¥ç‚¹æ•°: {num_tickets}ç‚¹")
    print(f"æŠ•è³‡é¡: {total_cost:,}å††")
    print(f"\nå„ãƒ¬ãƒ¼ã‚¹ã®æœ¬å‘½é¦¬:")
    for race_num in target_races:
        print(f"  ç¬¬{race_num}R: {'-'.join(map(str, top_horses[race_num]))}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    output_path = "predictions/æ±äº¬_20260216_win5.txt"
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(f"WIN5è²·ã„ç›®\n")
        f.write(f"å¯¾è±¡ãƒ¬ãƒ¼ã‚¹: ç¬¬{target_races[0]}R ã€œ ç¬¬{target_races[-1]}R\n")
        f.write(f"è³¼å…¥ç‚¹æ•°: {num_tickets}ç‚¹\n")
        f.write(f"æŠ•è³‡é¡: {total_cost:,}å††\n\n")
        for i, combo in enumerate(combinations, 1):
            f.write(f"{i:3d}. {'-'.join(map(str, combo))}\n")
    
    print(f"\nâœ… ä¿å­˜å®Œäº†: {output_path}")

if __name__ == "__main__":
    ensemble_csv = "data/predictions/phase5/temp_20260216_ensemble.csv"
    generate_win5_tickets(ensemble_csv)
```

---

## 6. å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Phase 0: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- [ ] æ–°è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
- [ ] GitåˆæœŸåŒ–
- [ ] README.mdä½œæˆ
- [ ] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ

### Phase 1: ãƒ‡ãƒ¼ã‚¿å–å¾—
- [ ] JRA-VAN Data Labå°å…¥ **ã¾ãŸã¯** netkeiba.comã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè£…
- [ ] 10ç«¶é¦¬å ´ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ
- [ ] ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆ1ç«¶é¦¬å ´ã€1æ—¥åˆ†ï¼‰

### Phase 2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
- [ ] æ—¢å­˜50ç‰¹å¾´é‡ã®æµç”¨
- [ ] JRAç‰¹æœ‰20ç‰¹å¾´é‡ã®è¿½åŠ 
- [ ] æ¬ æå€¤å‡¦ç†ã®å®Ÿè£…

### Phase 3-5: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»äºˆæ¸¬ãƒ»ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
- [ ] 10ç«¶é¦¬å ´åˆ¥ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆPhase 3ï¼‰
- [ ] ãƒ©ãƒ³ã‚­ãƒ³ã‚°äºˆæ¸¬å®Ÿè£…ï¼ˆPhase 4-1ï¼‰
- [ ] å›å¸°äºˆæ¸¬å®Ÿè£…ï¼ˆPhase 4-2ï¼‰
- [ ] ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆå®Ÿè£…ï¼ˆPhase 5ï¼‰

### Phase 6: é…ä¿¡ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
- [ ] Note/ãƒ–ãƒƒã‚«ãƒ¼ã‚º/Twitterç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…
- [ ] WIN5è²·ã„ç›®ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…

### Phase 7-10: é«˜åº¦åŒ–æ©Ÿèƒ½
- [ ] Greedy Borutaç‰¹å¾´é‡é¸æŠ
- [ ] Optunaè‡ªå‹•æœ€é©åŒ–
- [ ] KellyåŸºæº–ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³
- [ ] ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ

---

## 7. ã¾ã¨ã‚

### âœ… ã“ã®æŒ‡ç¤ºæ›¸ã®ä½¿ã„æ–¹

1. **æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚**
   - ã“ã®æŒ‡ç¤ºæ›¸ã®å…¨æ–‡ã‚’AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã«æç¤º
   - GitHubãƒªãƒã‚¸ãƒˆãƒªã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã¯ä¸è¦
   - æŒ‡ç¤ºæ›¸å†…ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’ãã®ã¾ã¾ä½¿ç”¨å¯èƒ½

2. **å®Ÿè£…ã®å„ªå…ˆé †ä½**
   - Phase 0ï¼ˆãƒ‡ãƒ¼ã‚¿å–å¾—ï¼‰ã‹ã‚‰é †æ¬¡å®Ÿè£…
   - å„Phaseã”ã¨ã«ãƒ†ã‚¹ãƒˆãƒ»æ¤œè¨¼
   - Phase 6ã§WIN5å¯¾å¿œã‚’å®Ÿè£…

3. **åœ°æ–¹ç«¶é¦¬ã‚·ã‚¹ãƒ†ãƒ ã¨ã®å·®åˆ†**
   - ç«¶é¦¬å ´æ•°: 14å ´ â†’ 10å ´
   - ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: PC-KEIBA â†’ JRA-VAN
   - ç‰¹å¾´é‡: 50å€‹ â†’ 70å€‹ï¼ˆèŠãƒ»ãƒ€ãƒ¼ãƒˆå¯¾å¿œï¼‰
   - è²·ã„ç›®: WIN5è¿½åŠ 

### ğŸš€ é–‹ç™ºé–‹å§‹ã‚³ãƒãƒ³ãƒ‰

```bash
# 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
mkdir jra-keiba-ai && cd jra-keiba-ai
git init

# 2. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p scripts/{phase0_data_acquisition,phase1_feature_engineering,phase3_binary,phase4_ranking,phase4_regression,phase5_ensemble,phase6_betting}
mkdir -p models/{binary,ranking,regression}
mkdir -p data/{raw,features,predictions}

# 3. Phase 0å®Ÿè£…é–‹å§‹
# ã“ã®æŒ‡ç¤ºæ›¸ã®ã€ŒStep 2: Phase 0å®Ÿè£…ã€ã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼
```

---

**ä½œæˆè€…**: Claude (AI Assistant)  
**ä½œæˆæ—¥**: 2026å¹´02æœˆ14æ—¥  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.0ï¼ˆæ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œå…¨å¯¾å¿œç‰ˆï¼‰  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: âœ… å®Œæˆ

---

**Ready to Start JRA Version Development! ğŸ‡ğŸ¯**
